---
title: "political-satire-r-charts"
author: "Anna Fetter"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(lubridate)
library(stringr)
library(hms)
library(readr)
library(readxl)
library(patchwork)
library(ggforce)
library(hms)
```

### Step 1. Read in the data
```{r}
snl_airtime <- read_csv("data/snl-airtime.csv")
View(snl_airtime)
```

```{r}
#setting a theme so all charts look cohesive
theme_academic <- function(base_size = 14, base_family = "") {
  theme_minimal(base_size = base_size, base_family = base_family) +
    theme(
      strip.text = element_text(face = "bold", size = 10),
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank(),
      panel.grid.major.y = element_blank(),
      panel.grid.minor.y = element_blank(),
      panel.grid.major.x = element_line(color = "grey80", linewidth = 0.3),
      panel.grid.minor.x = element_line(color = "grey90", linewidth = 0.2),
      plot.title = element_text(face = "bold", size = 16, hjust = 0.5),
      plot.subtitle = element_text(size = 12, hjust = 0.5),
      axis.text.x = element_text(size = 10, color = "black"),
      plot.background = element_rect(fill = "white", color = NA)
    )
}
# Add a fixed aspect ratio to your chart
coord_fixed(ratio = 0.1)  # Adjust the ratio as needed

# Set the custom theme globally
theme_set(theme_academic())

# wrapper function to save charts with consistent dimensions
# Wrapper function for consistent chart styling and saving
save_academic_chart <- function(plot, filename, width = 8, height = 11, dpi = 300) {
  plot <- plot + theme_academic()  # Apply the custom theme without coord_fixed()
  ggsave(filename, plot = plot, width = width, height = height, dpi = dpi)
}
```
```{r}
#read in other chart for topic analysis
snl_topics <- read_excel("data/SNL-topics.xlsx")
View(snl_topics)
```

```{r}
class(snl_airtime$`harris air time stamps`)
```

```{r}
# cleaning the data to capture total airtime for Trump & Harris

# Function to calculate duration from timestamp ranges
calculate_duration <- function(time_range) {
  if (is.na(time_range) || time_range == "none" || time_range == "") return(0)
  
  # Process multiple ranges separated by "and"
  ranges <- unlist(strsplit(time_range, " and "))
  total_seconds <- 0
  
  for (range in ranges) {
    # Split start and end times
    times <- unlist(strsplit(range, "-"))
    if (length(times) != 2) next  # Skip invalid ranges
    
    # Convert start time to seconds
    start_parts <- as.numeric(unlist(strsplit(times[1], ":")))
    start_seconds <- if (length(start_parts) == 3) {
      start_parts[1] * 3600 + start_parts[2] * 60 + start_parts[3]  # HH:MM:SS
    } else if (length(start_parts) == 2) {
      start_parts[1] * 60 + start_parts[2]  # MM:SS
    } else {
      start_parts[1]  # Seconds only
    }
    
    # Convert end time to seconds
    end_parts <- as.numeric(unlist(strsplit(times[2], ":")))
    end_seconds <- if (length(end_parts) == 3) {
      end_parts[1] * 3600 + end_parts[2] * 60 + end_parts[3]  # HH:MM:SS
    } else if (length(end_parts) == 2) {
      end_parts[1] * 60 + end_parts[2]  # MM:SS
    } else {
      end_parts[1]  # Seconds only
    }
    
    # Check for valid start and end times
    if (is.na(start_seconds) || is.na(end_seconds) || start_seconds > end_seconds) {
      warning(paste("Invalid time range:", range))
      next  # Skip invalid ranges
    }
    
    # Add duration to total
    total_seconds <- total_seconds + (end_seconds - start_seconds)
  }
  
  return(total_seconds)
}

# Function to process timestamps into a dataframe of start and end times
process_timestamps <- function(timestamps, candidate) {
  if (is.na(timestamps) || timestamps == "none" || timestamps == "") {
    # Return an empty dataframe with the correct structure
    return(data.frame(start = numeric(0), end = numeric(0), candidate = character(0)))
  }
  
  # Split the timestamps by "and" to handle multiple ranges
  ranges <- unlist(strsplit(timestamps, " and "))
  segments <- data.frame()
  
  for (range in ranges) {
    # Split each range into start and end times
    times <- unlist(strsplit(range, "-"))
    if (length(times) != 2) next
    
    # Convert start and end times to seconds
    start_parts <- as.numeric(unlist(strsplit(times[1], ":")))
    start_seconds <- if (length(start_parts) == 2) start_parts[1] * 60 + start_parts[2] else start_parts[1]
    
    end_parts <- as.numeric(unlist(strsplit(times[2], ":")))
    end_seconds <- if (length(end_parts) == 2) end_parts[1] * 60 + end_parts[2] else end_parts[1]
    
    # Add the segment to the dataframe
    segment <- data.frame(
      start = start_seconds,
      end = end_seconds,
      candidate = candidate
    )
    segments <- rbind(segments, segment)
  }
  
  return(segments)
}

str(snl_airtime$date)
```

### Airtime visualization for SNL
```{r}
# === PROCESSING SNL AIRTIME DATA ===

snl_airtime_processed <- snl_airtime %>%
  mutate(
    total_trump_airtime_seconds = sapply(`trump air time stamps`, calculate_duration),
    total_harris_airtime_seconds = sapply(`harris air time stamps`, calculate_duration),
    total_trump_airtime_minutes = round(total_trump_airtime_seconds / 60, 2),
    total_harris_airtime_minutes = round(total_harris_airtime_seconds / 60, 2),
    episode_length_seconds = sapply(`run time (total)`, function(runtime) {
      time_parts <- unlist(strsplit(as.character(runtime), ":"))
      if (length(time_parts) == 3) {
        as.numeric(time_parts[1]) * 3600 + as.numeric(time_parts[2]) * 60 + as.numeric(time_parts[3])
      } else if (length(time_parts) == 2) {
        as.numeric(time_parts[1]) * 60 + as.numeric(time_parts[2])
      } else {
        as.numeric(time_parts[1])
      }
    }),
    date = as.Date(date, format = "%d-%b-%y")
  )

# Build SNL segments
snl_all_segments <- data.frame(
  start = numeric(0),
  end = numeric(0),
  candidate = character(0),
  episode = character(0),
  stringsAsFactors = FALSE
)

for (i in 1:nrow(snl_airtime_processed)) {
  episode <- snl_airtime_processed[i, ]
  episode_title <- paste0(
    str_remove(episode$show, "SNL "),
    " (", format(episode$date, "%b %d, %Y"), ")"
  )

  trump_segments <- process_timestamps(episode$`trump air time stamps`, "Trump")
  harris_segments <- process_timestamps(episode$`harris air time stamps`, "Harris")

  if (nrow(trump_segments) > 0) {
    trump_segments$episode <- episode_title
    snl_all_segments <- rbind(snl_all_segments, trump_segments)
  }

  if (nrow(harris_segments) > 0) {
    harris_segments$episode <- episode_title
    snl_all_segments <- rbind(snl_all_segments, harris_segments)
  }
}

# Clean and build episode bars
snl_episode_bars <- snl_airtime_processed %>%
  mutate(
    episode = paste0(
      str_remove(show, "SNL "),
      " (", format(date, "%b %d, %Y"), ")"
    ),
    episode_index = row_number()
  ) %>%
  select(episode, episode_length_seconds, date, episode_index) %>%
  mutate(
    episode = gsub("\"", "'", episode),
    episode = gsub("’", "'", episode),
    episode = gsub("“|”", "'", episode),
    episode = str_trim(episode)
  )

snl_all_segments <- snl_all_segments %>%
  mutate(
    episode = gsub("\"", "'", episode),
    episode = gsub("’", "'", episode),
    episode = gsub("“|”", "'", episode),
    episode = str_trim(episode)
  )

snl_all_segments <- snl_all_segments %>%
  left_join(
    snl_episode_bars %>% select(episode, episode_index),
    by = "episode"
  )

# === FACETED PLOTTING (TLS STYLE, WITH DUMMY PANELS) ===

episodes_per_page <- 12
total_pages <- ceiling(nrow(snl_episode_bars) / episodes_per_page)

for (page in 1:total_pages) {
  page_indices <- ((page - 1) * episodes_per_page + 1):min(page * episodes_per_page, nrow(snl_episode_bars))
  
  # Real episodes
  page_bars <- snl_episode_bars %>%
    filter(episode_index %in% page_indices) %>%
    mutate(label = episode, is_dummy = FALSE)

  page_segments <- snl_all_segments %>%
    filter(episode_index %in% page_indices) %>%
    left_join(page_bars %>% select(episode, label), by = "episode")

  # Add dummy panels if needed
  if (nrow(page_bars) < episodes_per_page) {
    dummy_count <- episodes_per_page - nrow(page_bars)
    dummy_labels <- paste0("dummy_", seq_len(dummy_count))
    invisible_labels <- strrep(" ", seq_len(dummy_count))  # visually blank but unique
    dummy_bars <- tibble(
      episode = dummy_labels,
      episode_length_seconds = 1,
      date = NA,
      episode_index = max(page_bars$episode_index, na.rm = TRUE) + seq_len(dummy_count),
      label = invisible_labels,
      is_dummy = TRUE
    )
    page_bars <- bind_rows(page_bars, dummy_bars)
  }

  page_bars$label <- factor(page_bars$label, levels = page_bars$label)
  page_segments$label <- factor(page_segments$label, levels = levels(page_bars$label))

  dummy_segments <- page_bars %>%
    filter(is_dummy) %>%
    mutate(start = NA_real_, end = NA_real_, candidate = "dummy") %>%
    select(label, start, end, candidate)

  all_page_segments <- bind_rows(page_segments, dummy_segments)

  paginated_vis <- ggplot() +
    geom_rect(
      data = page_bars %>% filter(!is_dummy),
      aes(xmin = 0, xmax = episode_length_seconds, ymin = 0, ymax = 1),
      fill = "grey90", color = "black", linewidth = 0.3
    ) +
    geom_rect(
      data = filter(all_page_segments, candidate == "Trump"),
      aes(xmin = start, xmax = end, ymin = 0.5, ymax = 1),
      fill = "#e74c3c", alpha = 0.8
    ) +
    geom_rect(
      data = filter(all_page_segments, candidate == "Harris"),
      aes(xmin = start, xmax = end, ymin = 0, ymax = 0.5),
      fill = "#2980b9", alpha = 0.8
    ) +
    geom_rect(
      data = filter(all_page_segments, candidate == "dummy"),
      aes(xmin = start, xmax = end, ymin = 0, ymax = 1),
      fill = NA, color = NA
    ) +
    scale_x_continuous(
      breaks = waiver(),
      labels = function(x) sprintf("%d:%02d", as.integer(x) %/% 60, as.integer(x) %% 60)
    ) +
    facet_wrap(~ label, ncol = 1, nrow = episodes_per_page, scales = "free_x") +
    labs(
      title = paste0("Saturday Night Live Candidate Airtime (Page ", page, " of ", total_pages, ")"),
      subtitle = "Red: Trump | Blue: Harris",
      x = "Time (minutes:seconds)",
      y = NULL
    ) +
    theme_minimal(base_size = 9) +
    theme(
      strip.text = element_text(size = 8, hjust = 0),
      strip.background = element_blank(),
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank(),
      axis.title.y = element_blank(),
      panel.grid = element_blank(),
      panel.spacing = unit(0.1, "lines"),
      plot.title = element_text(size = 10, face = "bold"),
      plot.subtitle = element_text(size = 8),
      plot.margin = margin(8, 8, 8, 8)
    )

  ggsave(
    filename = paste0("snl_airtime_page", page, ".jpeg"),
    plot = paginated_vis,
    width = 7,
    height = 10.5,
    dpi = 300,
    device = "jpeg"
  )
}

```

### Topic analysis for snl
```{r}
#Now we're moving onto topic analysis, we need to clean the data first
# Convert "run time (total)" from POSIXct to seconds and MM:SS, THIS IS BROKEN
snl_topics_processed <- snl_topics %>%
  mutate(
    # Extract minutes and seconds from the POSIXct object
    episode_length_seconds = as.numeric(format(`run time (total)`, "%M")) * 60 +
                             as.numeric(format(`run time (total)`, "%S")),
    
    # Format back to MM:SS for display
    episode_length_formatted = sprintf("%d:%02d", floor(episode_length_seconds / 60), episode_length_seconds %% 60)
  )

#I noticed that the episode length is reading in as a date: fixing so it's run time
str(snl_topics$`run time (total)`)
```

## Cleaning topic analysis into a quantifiable format
```{r}
# step 1. make data quantifiable (ex. direct mentions = True, no direct mentions = False)
snl_topics_processed <- snl_topics %>%
  mutate(across(
    contains(c("reproductive", "immigration", "economics", "democracy")),
    ~ case_when(
        str_detect(., regex("no (direct|mentions|statements)", ignore_case = TRUE)) ~ FALSE,
        is.na(.) ~ NA,
        TRUE ~ TRUE
      ),
    .names = "mentioned_{.col}"
  ))
```


```{r}

#coding on my own to create the heatmap data

snl_heatmap_data <- snl_topics_processed %>% 
  mutate(
    economics = case_when(
      `mentioned_Trump Economics` == TRUE & `mentioned_Harris Economics` == FALSE ~ "Trump",
      `mentioned_Trump Economics` == FALSE & `mentioned_Harris Economics` == TRUE ~ "Harris",
      `mentioned_Trump Economics` == TRUE & `mentioned_Harris Economics` == TRUE ~ "Both",
      TRUE ~ "None"  # Default case when neither is TRUE
    ),
    reproductive_rights = case_when(
      `mentioned_Trump reproductive rights` == TRUE & `mentioned_Harris reproductive rights` == FALSE ~ "Trump",
      `mentioned_Trump reproductive rights` == FALSE & `mentioned_Harris reproductive rights` == TRUE ~ "Harris",
      `mentioned_Trump reproductive rights` == TRUE & `mentioned_Harris reproductive rights` == TRUE ~ "Both",
      TRUE ~ "None"  # Default case when neither is TRUE
    ),
    immigration = case_when(
      `mentioned_Trump immigration` == TRUE & `mentioned_Harris immigration` == FALSE ~ "Trump",
      `mentioned_Trump immigration` == FALSE & `mentioned_Harris immigration` == TRUE ~ "Harris",
      `mentioned_Trump immigration` == TRUE & `mentioned_Harris immigration` == TRUE ~ "Both",
      TRUE ~ "None"  # Default case when neither is TRUE
    ),
    democracy = case_when(
      `mentioned_Trump Democracy` == TRUE & `mentioned_Harris Democracy` == FALSE ~ "Trump",
      `mentioned_Trump Democracy` == FALSE & `mentioned_Harris Democracy` == TRUE ~ "Harris",
      `mentioned_Trump Democracy` == TRUE & `mentioned_Harris Democracy` == TRUE ~ "Both",
      TRUE ~ "None"  # Default case when neither is TRUE
    )
  ) %>% 
  select(show, date, economics, reproductive_rights, immigration, democracy)

head(snl_heatmap_data)
```

```{r}

# First, build labels like: 1 (Oct 01)
snl_heatmap_data <- snl_heatmap_data %>%
  arrange(date) %>%
  mutate(
    ep_num = row_number(),
    ep_label = paste0(ep_num, " (", format(date, "%b %d"), ")")
  )

# Pivot to long format for plotting
heatmap_long <- snl_heatmap_data %>%
  pivot_longer(
    cols = c(economics, reproductive_rights, immigration, democracy),
    names_to = "topic",
    values_to = "mentioned_by"
  )

# Color mapping
mention_colors <- c(
  "Trump" = "red",
  "Harris" = "blue",
  "Both" = "purple",
  "None" = "grey90"
)

# Build the heatmap
snl_heatmap_plot <- ggplot(heatmap_long, aes(x = factor(ep_label, levels = unique(snl_heatmap_data$ep_label)), 
                                         y = fct_rev(topic), fill = mentioned_by)) +
  geom_tile(color = "white", linewidth = 0.5) +
  scale_fill_manual(values = mention_colors, name = "Mentioned By") +
  labs(
    title = "Saturday Night Live Mentions by Topic and Candidate",
    x = "Episode Number (Air Date)",
    y = "Topic"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid = element_blank(),
    plot.background = element_rect(fill = "white", color = NA)
  ) +
  geom_vline(
    xintercept = which(snl_heatmap_data$date == as.Date("2024-11-05")),
    linetype = "dashed", color = "black"
  )

# Save the final version
ggsave("snl_heatmap_topics.png", plot = snl_heatmap_plot, width = 12, height = 6, dpi = 300)
```

## Repeat the analysis for LWT
```{r}
# Read in data
LWT_airtime <- read_csv("data/LWT-airtime.csv")
LWT_topics <- read_excel("data/LWT-topics.xlsx")
```

```{r}
summary(LWT_airtime)
```

```{r}
# Step 1: Process the LWT airtime data with corrected runtime parsing for HH:MM:SS
LWT_airtime_processed <- LWT_airtime %>%
  mutate(
    # Correctly parse "run time (total)" from HH:MM:SS to total seconds
    episode_length_seconds = sapply(`run time (total)`, function(runtime) {
      time_parts <- unlist(strsplit(as.character(runtime), ":"))
      # Handle HH:MM:SS format
      if (length(time_parts) == 3) {
        as.numeric(time_parts[1]) * 3600 +  # Hours to seconds
        as.numeric(time_parts[2]) * 60 +   # Minutes to seconds
        as.numeric(time_parts[3])          # Seconds
      } else if (length(time_parts) == 2) {
        as.numeric(time_parts[1]) * 60 +   # Minutes to seconds
        as.numeric(time_parts[2])          # Seconds
      } else {
        as.numeric(time_parts[1])          # Seconds only
      }
    }),
    
    # Calculate total airtime in seconds for Trump and Harris
    total_trump_airtime_seconds = sapply(`trump air time stamps`, calculate_duration),
    total_harris_airtime_seconds = sapply(`harris air time stamps`, calculate_duration),
    
    # Convert airtime to minutes for easier interpretation
    total_trump_airtime_minutes = round(total_trump_airtime_seconds / 60, 2),
    total_harris_airtime_minutes = round(total_harris_airtime_seconds / 60, 2)
  )

# Convert the date column to Date format
LWT_airtime_processed <- LWT_airtime_processed %>%
  mutate(date = as.Date(date, format = "%d-%b-%y"))
```

```{r}
#create airtime visualizations
# Step 2: Process all episodes into segments
all_segments_lwt <- data.frame(
  start = numeric(0),
  end = numeric(0), 
  candidate = character(0),
  episode = character(0),
  stringsAsFactors = FALSE
)

for (i in 1:nrow(LWT_airtime_processed)) {
  episode <- LWT_airtime_processed[i, ]
  episode_title <- paste0(
    episode$show,
    " (", format(episode$date, "%b %d, %Y"), ")"
  )
  
  # Process Trump and Harris airtime
  trump_segments <- process_timestamps(episode$`trump air time stamps`, "Trump")
  harris_segments <- process_timestamps(episode$`harris air time stamps`, "Harris")
  
  # Add episode title to each segment
  if (nrow(trump_segments) > 0) {
    trump_segments$episode <- episode_title
    all_segments_lwt <- rbind(all_segments_lwt, trump_segments)
  }
  
  if (nrow(harris_segments) > 0) {
    harris_segments$episode <- episode_title
    all_segments_lwt <- rbind(all_segments_lwt, harris_segments)
  }
}
```

```{r}
# Check the structure of the date column
str(LWT_airtime_processed$date)

# View unique values in the date column
unique(LWT_airtime_processed$date)
```

```{r}
# Create episode index for pagination
episode_bars_lwt <- LWT_airtime_processed %>%
  mutate(
    episode = paste0(
      show,
      " (", format(date, "%b %d, %Y"), ")"
    ),
    episode_index = row_number()
  ) %>%
  select(episode, episode_length_seconds, date, episode_index) %>%
  mutate(
    episode = gsub("\"", "'", episode),
    episode = gsub("’", "'", episode),
    episode = gsub("“|”", "'", episode),
    episode = str_trim(episode)
  )

all_segments_lwt <- all_segments_lwt %>%
  mutate(
    episode = gsub("\"", "'", episode),
    episode = gsub("’", "'", episode),
    episode = gsub("“|”", "'", episode),
    episode = str_trim(episode)
  ) %>%
  left_join(
    episode_bars_lwt %>% select(episode, episode_index),
    by = "episode"
  )

# === PAGINATED FACETED PLOTS FOR LWT ===

episodes_per_page <- 12
total_pages <- ceiling(nrow(episode_bars_lwt) / episodes_per_page)

for (page in 1:total_pages) {
  page_indices <- ((page - 1) * episodes_per_page + 1):min(page * episodes_per_page, nrow(episode_bars_lwt))
  
  # Real episodes
  page_bars <- episode_bars_lwt %>%
    filter(episode_index %in% page_indices) %>%
    mutate(label = episode, is_dummy = FALSE)

  page_segments <- all_segments_lwt %>%
    filter(episode_index %in% page_indices) %>%
    left_join(page_bars %>% select(episode, label), by = "episode")

  # Add dummy rows if needed
  if (nrow(page_bars) < episodes_per_page) {
    dummy_count <- episodes_per_page - nrow(page_bars)
    dummy_labels <- paste0("dummy_", seq_len(dummy_count))
    invisible_labels <- strrep(" ", seq_len(dummy_count))
    dummy_bars <- tibble(
      episode = dummy_labels,
      episode_length_seconds = 1,
      date = NA,
      episode_index = max(page_bars$episode_index, na.rm = TRUE) + seq_len(dummy_count),
      label = invisible_labels,
      is_dummy = TRUE
    )
    page_bars <- bind_rows(page_bars, dummy_bars)
  }

  # Set facet order
  page_bars$label <- factor(page_bars$label, levels = page_bars$label)
  page_segments$label <- factor(page_segments$label, levels = levels(page_bars$label))

  # Dummy segments
  dummy_segments <- page_bars %>%
    filter(is_dummy) %>%
    mutate(start = NA_real_, end = NA_real_, candidate = "dummy") %>%
    select(label, start, end, candidate)

  all_page_segments <- bind_rows(page_segments, dummy_segments)

  # Plot
  paginated_vis <- ggplot() +
    geom_rect(
      data = page_bars %>% filter(!is_dummy),
      aes(xmin = 0, xmax = episode_length_seconds, ymin = 0, ymax = 1),
      fill = "grey90", color = "black", linewidth = 0.3
    ) +
    geom_rect(
      data = filter(all_page_segments, candidate == "Trump"),
      aes(xmin = start, xmax = end, ymin = 0.5, ymax = 1),
      fill = "#e74c3c", alpha = 0.8
    ) +
    geom_rect(
      data = filter(all_page_segments, candidate == "Harris"),
      aes(xmin = start, xmax = end, ymin = 0, ymax = 0.5),
      fill = "#2980b9", alpha = 0.8
    ) +
    geom_rect(
      data = filter(all_page_segments, candidate == "dummy"),
      aes(xmin = start, xmax = end, ymin = 0, ymax = 1),
      fill = NA, color = NA
    ) +
    scale_x_continuous(
      breaks = waiver(),
      labels = function(x) sprintf("%d:%02d", as.integer(x) %/% 60, as.integer(x) %% 60)
    ) +
    facet_wrap(~ label, ncol = 1, nrow = episodes_per_page, scales = "free_x") +
    labs(
      title = paste0("Last Week Tonight Candidate Airtime (Page ", page, " of ", total_pages, ")"),
      subtitle = "Red: Trump | Blue: Harris",
      x = "Time (minutes:seconds)",
      y = NULL
    ) +
    theme_minimal(base_size = 9) +
    theme(
      strip.text = element_text(size = 8, hjust = 0),
      strip.background = element_blank(),
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank(),
      axis.title.y = element_blank(),
      panel.grid = element_blank(),
      panel.spacing = unit(0.1, "lines"),
      plot.title = element_text(size = 10, face = "bold"),
      plot.subtitle = element_text(size = 8),
      plot.margin = margin(8, 8, 8, 8)
    )

  ggsave(
    filename = paste0("lwt_airtime_page", page, ".jpeg"),
    plot = paginated_vis,
    width = 7,
    height = 10.5,
    dpi = 300,
    device = "jpeg"
  )
}

```

```{r}
#now creating the topic heatmap for LWT
# Step 1: Process the LWT topics data
LWT_topics_processed <- LWT_topics %>%
  mutate(across(
    contains(c("reproductive", "immigration", "economics", "democracy")),
    ~ case_when(
        str_detect(., regex("No (mention|statements)", ignore_case = TRUE)) ~ FALSE,  # Match "no mentions" or "no statements"
        is.na(.) ~ NA,  # Keep NA as NA
        TRUE ~ TRUE  # Everything else is TRUE
      ),
    .names = "mentioned_{.col}"  # Create new columns with "mentioned_" prefix
  ))

# Create heatmap data
# Step 2: Create the heatmap dataset
lwt_heatmap_data <- LWT_topics_processed %>%
  mutate(
    economics = case_when(
      `mentioned_Trump Economics` == TRUE & `mentioned_Harris Economics` == FALSE ~ "Trump",
      `mentioned_Trump Economics` == FALSE & `mentioned_Harris Economics` == TRUE ~ "Harris",
      `mentioned_Trump Economics` == TRUE & `mentioned_Harris Economics` == TRUE ~ "Both",
      TRUE ~ "None"  # Default case when neither is TRUE
    ),
    reproductive_rights = case_when(
      `mentioned_Trump reproductive rights` == TRUE & `mentioned_Harris reproductive rights` == FALSE ~ "Trump",
      `mentioned_Trump reproductive rights` == FALSE & `mentioned_Harris reproductive rights` == TRUE ~ "Harris",
      `mentioned_Trump reproductive rights` == TRUE & `mentioned_Harris reproductive rights` == TRUE ~ "Both",
      TRUE ~ "None"  # Default case when neither is TRUE
    ),
    immigration = case_when(
      `mentioned_Trump immigration` == TRUE & `mentioned_Harris immigration` == FALSE ~ "Trump",
      `mentioned_Trump immigration` == FALSE & `mentioned_Harris immigration` == TRUE ~ "Harris",
      `mentioned_Trump immigration` == TRUE & `mentioned_Harris immigration` == TRUE ~ "Both",
      TRUE ~ "None"  # Default case when neither is TRUE
    ),
    democracy = case_when(
      `mentioned_Trump Democracy` == TRUE & `mentioned_Harris Democracy` == FALSE ~ "Trump",
      `mentioned_Trump Democracy` == FALSE & `mentioned_Harris Democracy` == TRUE ~ "Harris",
      `mentioned_Trump Democracy` == TRUE & `mentioned_Harris Democracy` == TRUE ~ "Both",
      TRUE ~ "None"  # Default case when neither is TRUE
    )
  ) %>%
  select(show, date, economics, reproductive_rights, immigration, democracy)

unique(LWT_topics$date)

lwt_heatmap_data <- lwt_heatmap_data %>%
  mutate(date = as.Date(date, format = "%d-%b-%y"))
  
# View the first few rows of the heatmap dataset
head(lwt_heatmap_data)
```

```{r}
# Step 3: Prepare the data for plotting
lwt_heatmap_data <- lwt_heatmap_data %>%
  arrange(date) %>%
  mutate(
    ep_num = row_number(),  # Create episode numbers
    ep_label = paste0(ep_num, " (", format(date, "%b %d"), ")")  # Create episode labels
  )



# Pivot to long format
heatmap_long <- lwt_heatmap_data %>%
  pivot_longer(
    cols = c(economics, reproductive_rights, immigration, democracy),
    names_to = "topic",
    values_to = "mentioned_by"
  )
```

```{r}
#create the heatmap
# Step 4: Create the heatmap
lwt_heatmap_plot <- ggplot(heatmap_long, 
                          aes(x = factor(ep_label, levels = unique(lwt_heatmap_data$ep_label)), 
                              y = fct_rev(topic), fill = mentioned_by)) +
  geom_tile(color = "white", linewidth = 0.5) +
  scale_fill_manual(values = mention_colors, name = "Mentioned By") +
  labs(
    title = "Last Week Tonight with John Oliver Mentions by Topic and Candidate",
    x = "Episode Number (Air Date)",
    y = "Topic"
  ) +
  theme_academic() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.y = element_text(size = 10, color = "black"), # Explicitly show y-axis text
    panel.grid = element_blank(),
    plot.background = element_rect(fill = "white", color = NA)
  )

# Print the heatmap
print(lwt_heatmap_plot)

# Save the heatmap
ggsave("lwt_heatmap_topics.png", plot = lwt_heatmap_plot, width = 12, height = 6, dpi = 300)
```

#now repeating the analysis for The Late Show with Stephen Colbert
```{r}
#read in data
tls_airtime <- read_csv("data/tls-airtime.csv")
tls_topics <- read_excel("data/tls-topics.xlsx")

# Fix the run time column in tls_airtime
tls_airtime <- tls_airtime %>%
  mutate(
    # Convert "run time (total)" from MM:SS to total seconds
    episode_length_seconds = sapply(`run time`, function(runtime) {
      time_parts <- unlist(strsplit(as.character(runtime), ":"))
      if (length(time_parts) == 2) {
        # Parse as MM:SS
        as.numeric(time_parts[1]) * 60 + as.numeric(time_parts[2])
      } else if (length(time_parts) == 3) {
        # Handle HH:MM:SS (if present)
        as.numeric(time_parts[1]) * 3600 + as.numeric(time_parts[2]) * 60 + as.numeric(time_parts[3])
      } else {
        NA  # Handle unexpected formats
      }
    })
  ) 
tls_airtime <- tls_airtime %>%
  mutate(date = as.Date(date, format = "%d-%b-%y"))
```

#airtime visualization
```{r}
# === STEP 1: Process The Late Show Airtime Data ===

tls_airtime_processed <- tls_airtime %>%
  mutate(
    total_trump_airtime_seconds = sapply(`trump air time stamps`, calculate_duration),
    total_harris_airtime_seconds = sapply(`harris air time stamps`, calculate_duration),
    total_trump_airtime_minutes = round(total_trump_airtime_seconds / 60, 2),
    total_harris_airtime_minutes = round(total_harris_airtime_seconds / 60, 2),
    episode_length_seconds = sapply(`run time`, function(runtime) {
      time_parts <- unlist(strsplit(as.character(runtime), ":"))
      if (length(time_parts) == 3) {
        as.numeric(time_parts[1]) * 3600 + as.numeric(time_parts[2]) * 60 + as.numeric(time_parts[3])
      } else if (length(time_parts) == 2) {
        as.numeric(time_parts[1]) * 60 + as.numeric(time_parts[2])
      } else {
        as.numeric(time_parts[1])
      }
    }),
    date = as.Date(date, format = "%d-%b-%y")
  )

# === STEP 2: Build Segments for Visualization ===

all_segments_tls <- data.frame(
  start = numeric(0),
  end = numeric(0),
  candidate = character(0),
  episode = character(0),
  stringsAsFactors = FALSE
)

for (i in 1:nrow(tls_airtime_processed)) {
  episode <- tls_airtime_processed[i, ]
  episode_title <- paste0(
    episode$show,
    " (", format(episode$date, "%b %d, %Y"), ")"
  )

  trump_segments <- process_timestamps(episode$`trump air time stamps`, "Trump")
  harris_segments <- process_timestamps(episode$`harris air time stamps`, "Harris")

  if (nrow(trump_segments) > 0) {
    trump_segments$episode <- episode_title
    all_segments_tls <- rbind(all_segments_tls, trump_segments)
  }

  if (nrow(harris_segments) > 0) {
    harris_segments$episode <- episode_title
    all_segments_tls <- rbind(all_segments_tls, harris_segments)
  }
}

# === STEP 3: Build Episode Bars with Cleaned Labels ===

episode_bars_tls <- tls_airtime_processed %>%
  mutate(
    episode = paste0(
      show,
      " (", format(date, "%b %d, %Y"), ")"
    ),
    episode_index = row_number()
  ) %>%
  select(episode, episode_length_seconds, date, episode_index) %>%
  mutate(
    episode = gsub("\"", "'", episode),
    episode = gsub("’", "'", episode),
    episode = gsub("“|”", "'", episode),
    episode = str_trim(episode)
  )

all_segments_tls <- all_segments_tls %>%
  mutate(
    episode = gsub("\"", "'", episode),
    episode = gsub("’", "'", episode),
    episode = gsub("“|”", "'", episode),
    episode = str_trim(episode)
  ) %>%
  left_join(
    episode_bars_tls %>% select(episode, episode_index),
    by = "episode"
  )

# === STEP 4: Paginated Visualization ===

episodes_per_page <- 12
total_pages <- ceiling(nrow(episode_bars_tls) / episodes_per_page)

for (page in 1:total_pages) {
  page_indices <- ((page - 1) * episodes_per_page + 1):min(page * episodes_per_page, nrow(episode_bars_tls))
  
  page_bars <- episode_bars_tls %>%
    filter(episode_index %in% page_indices) %>%
    mutate(label = episode, is_dummy = FALSE)

  page_segments <- all_segments_tls %>%
    filter(episode_index %in% page_indices) %>%
    left_join(page_bars %>% select(episode, label), by = "episode")

  # Add dummy rows if needed
  if (nrow(page_bars) < episodes_per_page) {
    dummy_count <- episodes_per_page - nrow(page_bars)
    dummy_labels <- paste0("dummy_", seq_len(dummy_count))
    invisible_labels <- strrep(" ", seq_len(dummy_count))
    dummy_bars <- tibble(
      episode = dummy_labels,
      episode_length_seconds = 1,
      date = NA,
      episode_index = max(page_bars$episode_index, na.rm = TRUE) + seq_len(dummy_count),
      label = invisible_labels,
      is_dummy = TRUE
    )
    page_bars <- bind_rows(page_bars, dummy_bars)
  }

  page_bars$label <- factor(page_bars$label, levels = page_bars$label)
  page_segments$label <- factor(page_segments$label, levels = levels(page_bars$label))

  dummy_segments <- page_bars %>%
    filter(is_dummy) %>%
    mutate(start = NA_real_, end = NA_real_, candidate = "dummy") %>%
    select(label, start, end, candidate)

  all_page_segments <- bind_rows(page_segments, dummy_segments)

  paginated_vis <- ggplot() +
    geom_rect(
      data = page_bars %>% filter(!is_dummy),
      aes(xmin = 0, xmax = episode_length_seconds, ymin = 0, ymax = 1),
      fill = "grey90", color = "black", linewidth = 0.3
    ) +
    geom_rect(
      data = filter(all_page_segments, candidate == "Trump"),
      aes(xmin = start, xmax = end, ymin = 0.5, ymax = 1),
      fill = "#e74c3c", alpha = 0.8
    ) +
    geom_rect(
      data = filter(all_page_segments, candidate == "Harris"),
      aes(xmin = start, xmax = end, ymin = 0, ymax = 0.5),
      fill = "#2980b9", alpha = 0.8
    ) +
    geom_rect(
      data = filter(all_page_segments, candidate == "dummy"),
      aes(xmin = start, xmax = end, ymin = 0, ymax = 1),
      fill = NA, color = NA
    ) +
    scale_x_continuous(
      breaks = waiver(),
      labels = function(x) sprintf("%d:%02d", as.integer(x) %/% 60, as.integer(x) %% 60)
    ) +
    facet_wrap(~ label, ncol = 1, nrow = episodes_per_page, scales = "free_x") +
    labs(
      title = paste0("The Late Show Candidate Airtime (Page ", page, " of ", total_pages, ")"),
      subtitle = "Red: Trump | Blue: Harris",
      x = "Time (minutes:seconds)",
      y = NULL
    ) +
    theme_minimal(base_size = 9) +
    theme(
      strip.text = element_text(size = 8, hjust = 0),
      strip.background = element_blank(),
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank(),
      axis.title.y = element_blank(),
      panel.grid = element_blank(),
      panel.spacing = unit(0.1, "lines"),
      plot.title = element_text(size = 10, face = "bold"),
      plot.subtitle = element_text(size = 8),
      plot.margin = margin(8, 8, 8, 8)
    )

  ggsave(
    filename = paste0("tls_airtime_page", page, ".jpeg"),
    plot = paginated_vis,
    width = 7,
    height = 10.5,
    dpi = 300,
    device = "jpeg"
  )
}
```

#now build topic visualizations for TLS
```{r}
# Step 1: Process the TLS topics data
tls_topics_processed <- tls_topics %>%
  mutate(across(
    contains(c("reproductive", "immigration", "economics", "democracy")),
    ~ case_when(
        str_detect(., regex("No (mention|statements|direct|specific)", ignore_case = TRUE)) ~ FALSE,
        is.na(.) ~ NA,
        TRUE ~ TRUE
      ),
    .names = "mentioned_{.col}"
  ))

# Step 2: Create the heatmap dataset
tls_heatmap_data <- tls_topics_processed %>%
  mutate(
    economics = case_when(
      `mentioned_Trump Economics` == TRUE & `mentioned_Harris Economics` == FALSE ~ "Trump",
      `mentioned_Trump Economics` == FALSE & `mentioned_Harris Economics` == TRUE ~ "Harris",
      `mentioned_Trump Economics` == TRUE & `mentioned_Harris Economics` == TRUE ~ "Both",
      TRUE ~ "None"  # Default case when neither is TRUE
    ),
    reproductive_rights = case_when(
      `mentioned_Trump reproductive rights` == TRUE & `mentioned_Harris reproductive rights` == FALSE ~ "Trump",
      `mentioned_Trump reproductive rights` == FALSE & `mentioned_Harris reproductive rights` == TRUE ~ "Harris",
      `mentioned_Trump reproductive rights` == TRUE & `mentioned_Harris reproductive rights` == TRUE ~ "Both",
      TRUE ~ "None"
    ),
    immigration = case_when(
      `mentioned_Trump immigration` == TRUE & `mentioned_Harris immigration` == FALSE ~ "Trump",
      `mentioned_Trump immigration` == FALSE & `mentioned_Harris immigration` == TRUE ~ "Harris",
      `mentioned_Trump immigration` == TRUE & `mentioned_Harris immigration` == TRUE ~ "Both",
      TRUE ~ "None"
    )
  ) %>%
  select(show, date, economics, reproductive_rights, immigration)

# Make sure date is in the correct format
tls_heatmap_data <- tls_heatmap_data %>%
  mutate(date = as.Date(date, format = "%d-%b-%y"))

# Step 3: Prepare the data for plotting
tls_heatmap_data <- tls_heatmap_data %>%
  arrange(date) %>%
  mutate(
    ep_num = row_number(),  # Create episode numbers
    ep_label = paste0(ep_num, " (", format(date, "%b %d"), ")")  # Create episode labels
  )

# Pivot to long format
tls_heatmap_long <- tls_heatmap_data %>%
  pivot_longer(
    cols = c(economics, reproductive_rights, immigration),
    names_to = "topic",
    values_to = "mentioned_by"
  )

# Step 4: Create the heatmap
# Fix for TLS heatmap
tls_heatmap_plot <- ggplot(tls_heatmap_long, 
                          aes(x = factor(ep_label, levels = unique(tls_heatmap_data$ep_label)), 
                              y = fct_rev(topic), fill = mentioned_by)) +
  geom_tile(color = "white", linewidth = 0.5) +
  scale_fill_manual(values = mention_colors, name = "Mentioned By") +
  labs(
    title = "The Late Show with Stephen Colbert Mentions by Topic and Candidate",
    x = "Episode Number (Air Date)",
    y = "Topic"
  ) +
  theme_academic() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.y = element_text(size = 10, color = "black"), # Explicitly show y-axis text
    panel.grid = element_blank(),
    plot.background = element_rect(fill = "white", color = NA)
  ) +
  geom_vline(
    xintercept = which(tls_heatmap_data$date == as.Date("2024-11-05")),
    linetype = "dashed", color = "black"
  )

# Print the heatmap
print(tls_heatmap_plot)

# Save the heatmap
ggsave("tls_heatmap_topics.png", plot = tls_heatmap_plot, width = 12, height = 6, dpi = 300)
```



# Visualizations for The Daily Show
```{r}
# read in data, WILL NEED TO CHANGE THIS DATA ONCE EMMA FINISHES PAST ELECTION DAY
#tds_airtime_election <- read_excel("data/tds-airtime-election.xlsx")
#tds_topics_election <- read_excel("data/tds-topics-election.xlsx")

tds_topics <- read_excel("data/tds-topics.xlsx")
tds_airtime <- read_excel("data/tds-airtime.xlsx")

tds_airtime$`run time (total)` <- as_hms(tds_airtime$`run time (total)`)

tds_airtime <- tds_airtime %>% 
  arrange(date)
```

#airtime visualization for TDS
```{r}
# === STEP 1: Process The Daily Show Airtime Data ===

tds_airtime_processed <- tds_airtime %>%
  mutate(
    total_trump_airtime_seconds = sapply(`trump air time stamps`, calculate_duration),
    total_harris_airtime_seconds = sapply(`harris air time stamps`, calculate_duration),
    total_trump_airtime_minutes = round(total_trump_airtime_seconds / 60, 2),
    total_harris_airtime_minutes = round(total_harris_airtime_seconds / 60, 2),
    episode_length_seconds = sapply(`run time (total)`, function(runtime) {
      time_parts <- unlist(strsplit(as.character(runtime), ":"))
      if (length(time_parts) == 3) {
        as.numeric(time_parts[1]) * 3600 + as.numeric(time_parts[2]) * 60 + as.numeric(time_parts[3])
      } else if (length(time_parts) == 2) {
        as.numeric(time_parts[1]) * 60 + as.numeric(time_parts[2])
      } else {
        as.numeric(time_parts[1])
      }
    }),
    date = as.Date(date, format = "%d-%b-%y")
  )

# === STEP 2: Build Segments for Visualization ===

all_segments_tds <- data.frame(
  start = numeric(0),
  end = numeric(0),
  candidate = character(0),
  episode = character(0),
  stringsAsFactors = FALSE
)

for (i in 1:nrow(tds_airtime_processed)) {
  episode <- tds_airtime_processed[i, ]
  episode_title <- paste0(
    episode$show,
    " (", format(episode$date, "%b %d, %Y"), ")"
  )

  trump_segments <- process_timestamps(episode$`trump air time stamps`, "Trump")
  harris_segments <- process_timestamps(episode$`harris air time stamps`, "Harris")

  if (nrow(trump_segments) > 0) {
    trump_segments$episode <- episode_title
    all_segments_tds <- rbind(all_segments_tds, trump_segments)
  }

  if (nrow(harris_segments) > 0) {
    harris_segments$episode <- episode_title
    all_segments_tds <- rbind(all_segments_tds, harris_segments)
  }
}

# === STEP 3: Build Episode Bars with Cleaned Labels ===

episode_bars_tds <- tds_airtime_processed %>%
  mutate(
    episode = paste0(
      show,
      " (", format(date, "%b %d, %Y"), ")"
    ),
    episode_index = row_number()
  ) %>%
  select(episode, episode_length_seconds, date, episode_index) %>%
  mutate(
    episode = gsub("\"", "'", episode),
    episode = gsub("’", "'", episode),
    episode = gsub("“|”", "'", episode),
    episode = str_trim(episode)
  )

all_segments_tds <- all_segments_tds %>%
  mutate(
    episode = gsub("\"", "'", episode),
    episode = gsub("’", "'", episode),
    episode = gsub("“|”", "'", episode),
    episode = str_trim(episode)
  ) %>%
  left_join(
    episode_bars_tds %>% select(episode, episode_index),
    by = "episode"
  )

# === STEP 4: Paginated Visualization ===

episodes_per_page <- 12
total_pages <- ceiling(nrow(episode_bars_tds) / episodes_per_page)

for (page in 1:total_pages) {
  page_indices <- ((page - 1) * episodes_per_page + 1):min(page * episodes_per_page, nrow(episode_bars_tds))
  
  page_bars <- episode_bars_tds %>%
    filter(episode_index %in% page_indices) %>%
    mutate(label = episode, is_dummy = FALSE)

  page_segments <- all_segments_tds %>%
    filter(episode_index %in% page_indices) %>%
    left_join(page_bars %>% select(episode, label), by = "episode")

  # Add dummy rows if needed
  if (nrow(page_bars) < episodes_per_page) {
    dummy_count <- episodes_per_page - nrow(page_bars)
    dummy_labels <- paste0("dummy_", seq_len(dummy_count))
    invisible_labels <- strrep(" ", seq_len(dummy_count))
    dummy_bars <- tibble(
      episode = dummy_labels,
      episode_length_seconds = 1,
      date = NA,
      episode_index = max(page_bars$episode_index, na.rm = TRUE) + seq_len(dummy_count),
      label = invisible_labels,
      is_dummy = TRUE
    )
    page_bars <- bind_rows(page_bars, dummy_bars)
  }

  page_bars$label <- factor(page_bars$label, levels = page_bars$label)
  page_segments$label <- factor(page_segments$label, levels = levels(page_bars$label))

  dummy_segments <- page_bars %>%
    filter(is_dummy) %>%
    mutate(start = NA_real_, end = NA_real_, candidate = "dummy") %>%
    select(label, start, end, candidate)

  all_page_segments <- bind_rows(page_segments, dummy_segments)

  paginated_vis <- ggplot() +
    geom_rect(
      data = page_bars %>% filter(!is_dummy),
      aes(xmin = 0, xmax = episode_length_seconds, ymin = 0, ymax = 1),
      fill = "grey90", color = "black", linewidth = 0.3
    ) +
    geom_rect(
      data = filter(all_page_segments, candidate == "Trump"),
      aes(xmin = start, xmax = end, ymin = 0.5, ymax = 1),
      fill = "#e74c3c", alpha = 0.8
    ) +
    geom_rect(
      data = filter(all_page_segments, candidate == "Harris"),
      aes(xmin = start, xmax = end, ymin = 0, ymax = 0.5),
      fill = "#2980b9", alpha = 0.8
    ) +
    geom_rect(
      data = filter(all_page_segments, candidate == "dummy"),
      aes(xmin = start, xmax = end, ymin = 0, ymax = 1),
      fill = NA, color = NA
    ) +
    scale_x_continuous(
      breaks = waiver(),
      labels = function(x) sprintf("%d:%02d", as.integer(x) %/% 60, as.integer(x) %% 60)
    ) +
    facet_wrap(~ label, ncol = 1, nrow = episodes_per_page, scales = "free_x") +
    labs(
      title = paste0("The Daily Show Candidate Airtime (Page ", page, " of ", total_pages, ")"),
      subtitle = "Red: Trump | Blue: Harris",
      x = "Time (minutes:seconds)",
      y = NULL
    ) +
    theme_minimal(base_size = 9) +
    theme(
      strip.text = element_text(size = 8, hjust = 0),
      strip.background = element_blank(),
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank(),
      axis.title.y = element_blank(),
      panel.grid = element_blank(),
      panel.spacing = unit(0.1, "lines"),
      plot.title = element_text(size = 10, face = "bold"),
      plot.subtitle = element_text(size = 8),
      plot.margin = margin(8, 8, 8, 8)
    )

  ggsave(
    filename = paste0("tds_airtime_page", page, ".jpeg"),
    plot = paginated_vis,
    width = 7,
    height = 10.5,
    dpi = 300,
    device = "jpeg"
  )
}


```

# Topic Visualization for TDS
```{r}
# Step 1: Process the TDS topics data
tds_topics_processed <- tds_topics %>%
  mutate(across(
    contains(c("reproductive", "immigration", "economics")),
    ~ case_when(
        str_detect(., regex("No (mention|statements|direct|specific)", ignore_case = TRUE)) ~ FALSE,
        is.na(.) ~ NA,
        TRUE ~ TRUE
      ),
    .names = "mentioned_{.col}"
  ))

# Step 2: Create the heatmap dataset
tds_heatmap_data <- tds_topics_processed %>%
  mutate(
    economics = case_when(
      `mentioned_Trump Economics` == TRUE & `mentioned_Harris Economics` == FALSE ~ "Trump",
      `mentioned_Trump Economics` == FALSE & `mentioned_Harris Economics` == TRUE ~ "Harris",
      `mentioned_Trump Economics` == TRUE & `mentioned_Harris Economics` == TRUE ~ "Both",
      TRUE ~ "None"  # Default case when neither is TRUE
    ),
    reproductive_rights = case_when(
      `mentioned_Trump reproductive rights` == TRUE & `mentioned_Harris reproductive rights` == FALSE ~ "Trump",
      `mentioned_Trump reproductive rights` == FALSE & `mentioned_Harris reproductive rights` == TRUE ~ "Harris",
      `mentioned_Trump reproductive rights` == TRUE & `mentioned_Harris reproductive rights` == TRUE ~ "Both",
      TRUE ~ "None"
    ),
    immigration = case_when(
      `mentioned_Trump immigration` == TRUE & `mentioned_Harris immigration` == FALSE ~ "Trump",
      `mentioned_Trump immigration` == FALSE & `mentioned_Harris immigration` == TRUE ~ "Harris",
      `mentioned_Trump immigration` == TRUE & `mentioned_Harris immigration` == TRUE ~ "Both",
      TRUE ~ "None"
    )
  ) %>%
  select(show, date, economics, reproductive_rights, immigration)

# Ensure the `date` column is in the correct format
tds_heatmap_data <- tds_heatmap_data %>%
  mutate(date = as.Date(date, format = "%Y-%m-%d"))

# Step 3: Prepare the data for plotting
tds_heatmap_data <- tds_heatmap_data %>%
  arrange(date) %>%
  mutate(
    ep_num = row_number(),  # Create episode numbers
    ep_label = paste0(ep_num, " (", format(date, "%b %d"), ")")  # Create episode labels
  )

# Pivot to long format
tds_heatmap_long <- tds_heatmap_data %>%
  pivot_longer(
    cols = c(economics, reproductive_rights, immigration),
    names_to = "topic",
    values_to = "mentioned_by"
  )

# Step 4: Create the heatmap
mention_colors <- c(
  "Trump" = "red",
  "Harris" = "blue",
  "Both" = "purple",
  "None" = "grey90"
)

tds_heatmap_plot <- ggplot(tds_heatmap_long, 
                          aes(x = factor(ep_label, levels = unique(tds_heatmap_data$ep_label)), 
                              y = fct_rev(topic), fill = mentioned_by)) +
  geom_tile(color = "white", linewidth = 0.5) +
  scale_fill_manual(values = mention_colors, name = "Mentioned By") +
  labs(
    title = "The Daily Show Mentions by Topic and Candidate",
    x = "Segment Number (Air Date)",
    y = "Topic"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.y = element_text(size = 10, color = "black"),
    panel.grid = element_blank(),
    plot.background = element_rect(fill = "white", color = NA)
  ) +
  geom_vline(
    xintercept = which(tds_heatmap_data$date == as.Date("2024-11-05")),
    linetype = "dashed", color = "black"
  )

# Print the heatmap
print(tds_heatmap_plot)

# Save the heatmap
ggsave("tds_heatmap_topics.png", plot = tds_heatmap_plot, width = 12, height = 6, dpi = 300)
```
# Graph analyzing how airtime and topics change based on if the host is male or female
```{r}
# Categorize host gender and calculate percentages
tds_host_gender <- tds_topics %>%
  #drop when there is no host gender
  filter(!grepl("none", `Gender of Host`, ignore.case = TRUE)) %>%
  mutate(Gender_Category = case_when(
    grepl("^female$", `Gender of Host`, ignore.case = TRUE) ~ "Female",
    grepl("^male$|mostly male", `Gender of Host`, ignore.case = TRUE) ~ "Male",
    TRUE ~ "Other"
  )) %>%
  count(Gender_Category) %>%
  mutate(Percent = round(n / sum(n) * 100, 1),
         Label = paste0(Gender_Category, ": ", n, " (", Percent, "%)"))

# Create pie chart
tds_host_gender_plot <- ggplot(tds_host_gender, aes(x = "", y = n, fill = Gender_Category)) +
  geom_col(width = 1, color = "white") +
  coord_polar(theta = "y") +
  labs(
    title = "Gender Breakdown of Hosts on TDS",
    fill = "Host Gender"
  ) +
  theme_void() +
  geom_text(aes(label = Label), position = position_stack(vjust = 0.5), color = "white", size = 4) +
  scale_fill_manual(values = c(
    "Female" = "#e91e63",   # pink
    "Male" = "#006400"     # dark green
  ))

# Save the heatmap
ggsave("tds_host_gender_plot.png", plot = tds_host_gender_plot, width = 12, height = 6, dpi = 300)
```

```{r}
unique(tds_topics$`Gender of Host`)
```

#Cumulative airtime visualization
```{r}

# Combine all processed airtime dataframes into one
combined_airtime <- bind_rows(
  snl_airtime_processed %>%
    select(date, total_trump_airtime_seconds, total_harris_airtime_seconds) %>%
    mutate(show = "SNL"),
  
  tls_airtime_processed %>%
    select(date, total_trump_airtime_seconds, total_harris_airtime_seconds) %>%
    mutate(show = "TLS"),
  
  LWT_airtime_processed %>%
    select(date, total_trump_airtime_seconds, total_harris_airtime_seconds) %>%
    mutate(show = "LWT"),
  
  tds_airtime_processed %>%
   select(date, total_trump_airtime_seconds, total_harris_airtime_seconds) %>%
    mutate(show = "TDS")
)

# Group by week and calculate total airtime for each candidate
weekly_airtime <- combined_airtime %>%
  mutate(week = floor_date(date, "week")) %>%  # Group by week
  group_by(week, show) %>%
  summarize(
    total_trump_airtime_seconds = sum(total_trump_airtime_seconds, na.rm = TRUE),
    total_harris_airtime_seconds = sum(total_harris_airtime_seconds, na.rm = TRUE),
    .groups = "drop"
  )

# Calculate percentage of airtime for each candidate
weekly_percentages <- weekly_airtime %>%
  mutate(
    total_candidate_airtime_seconds = total_trump_airtime_seconds + total_harris_airtime_seconds,
    percent_harris = ifelse(total_candidate_airtime_seconds > 0,
                            (total_harris_airtime_seconds / total_candidate_airtime_seconds) * 100,
                            NA),
    percent_trump = 100 - percent_harris  # Remaining percentage for Trump
  ) %>%
  select(week, show, percent_harris, percent_trump)

# Combine into one row per week with both candidate shares
average_weekly_percentages <- weekly_percentages %>%
  group_by(week) %>%
  summarize(
    avg_percent_harris = mean(percent_harris, na.rm = TRUE),
    avg_percent_trump = mean(percent_trump, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  pivot_longer(
    cols = c(avg_percent_harris, avg_percent_trump),
    names_to = "candidate",
    values_to = "percentage"
  ) %>%
  mutate(
    candidate = recode(candidate, 
                       "avg_percent_harris" = "Harris", 
                       "avg_percent_trump" = "Trump")
  )

# Get the position of the election week factor on the Y-axis
election_week <- as.Date("2024-11-05")
election_week_floor <- floor_date(election_week, "week")

# Convert weeks to factor in the same order used in the plot
week_levels <- sort(unique(average_weekly_percentages$week), decreasing = TRUE)
election_week_index <- which(week_levels == election_week_floor)

# Now plot with a horizontal line at that Y-position
airtime_by_week <- ggplot(average_weekly_percentages, aes(x = percentage, y = fct_rev(as.factor(week)), fill = candidate)) +
  geom_col(position = "stack", alpha = 0.9) +
  geom_hline(yintercept = election_week_index, linetype = "dashed", color = "black", size = 1) +  # Election Day line
  annotate("text", x = 100, y = election_week_index, label = "Election Day", hjust = 0, vjust = -0.5, size = 4, color = "black") +
  scale_x_continuous(labels = function(x) paste0(x, "%"), limits = c(0, 100)) +
  labs(
    title = "Weekly Distribution of Airtime Between Trump and Harris",
    subtitle = "Averaged across Saturday Night Live, The Late Show, Last Week Tonight, and the Daily Show",
    x = "Share of Candidate Airtime",
    y = "Week"
  ) +
  scale_fill_manual(values = c("Trump" = "red", "Harris" = "blue")) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 10),
    plot.title = element_text(face = "bold", size = 16, hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5)
  ) + coord_cartesian(clip = "off")


# Print the plot
print(airtime_by_week)

ggsave(
  filename = "weekly_airtime_distribution.png",
  plot = airtime_by_week,
  width = 12,
  height = 8,
  dpi = 300
)
```

## Topic Visualizations

```{r}
# Combine all heatmap dataframes into one
combined_topics <- bind_rows(
  snl_heatmap_data %>%
    select(show, economics, reproductive_rights, immigration) %>%
    pivot_longer(cols = c(economics, reproductive_rights, immigration), names_to = "topic", values_to = "mentioned_by") %>%
    mutate(show = "SNL"),
  
  tls_heatmap_data %>%
    select(show, economics, reproductive_rights, immigration) %>%
    pivot_longer(cols = c(economics, reproductive_rights, immigration), names_to = "topic", values_to = "mentioned_by") %>%
    mutate(show = "TLS"),
  
  lwt_heatmap_data %>%
    select(show, economics, reproductive_rights, immigration) %>%
    pivot_longer(cols = c(economics, reproductive_rights, immigration), names_to = "topic", values_to = "mentioned_by") %>%
    mutate(show = "LWT"),
  tds_heatmap_data %>%
    select(show, economics, reproductive_rights, immigration) %>%
    pivot_longer(cols = c(economics, reproductive_rights, immigration), names_to = "topic", values_to = "mentioned_by") %>%
    mutate(show = "TDS")
)

# Group by topic and candidate, and count mentions
total_mentions <- combined_topics %>%
  filter(mentioned_by != "None") %>%  # Exclude rows where no candidate was mentioned
  group_by(topic, mentioned_by) %>%
  summarize(total_mentions = n(), .groups = "drop")

#to put "both" in the middle
total_mentions <- total_mentions %>%
  mutate(
    mentioned_by = factor(mentioned_by, levels = c("Trump", "Both", "Harris"))
  )

# Create the stacked bar chart
stacked_bar_chart <- ggplot(total_mentions, aes(x = topic, y = total_mentions, fill = mentioned_by)) +
  geom_bar(stat = "identity", position = "stack", alpha = 0.9) +
  scale_fill_manual(values = c("Trump" = "red", "Harris" = "blue", "Both" = "purple")) +
  labs(
    title = "Total Mentions of 2024 Election Topics by Candidate",
    subtitle = "Aggregated across SNL, TLS, LWT, & TDS",
    x = "Topic",
    y = "Total Mentions",
    fill = "Candidate"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(face = "bold", size = 16, hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5)
  )

# Print the chart
print(stacked_bar_chart)

# Save the chart
ggsave("total_mentions_by_topic.png", plot = stacked_bar_chart, width = 12, height = 8, dpi = 300)
```

# Combine all heatmap dataframes into one, including the date column
```{r}
#these are for the date based topic visualizations
# Ensure the `date` column is in Date format for all heatmap dataframes
snl_heatmap_data <- snl_heatmap_data %>%
  mutate(date = as.Date(date, format = "%Y-%m-%d"))  # Adjust the format if needed

tls_heatmap_data <- tls_heatmap_data %>%
  mutate(date = as.Date(date, format = "%Y-%m-%d"))  # Adjust the format if needed

lwt_heatmap_data <- lwt_heatmap_data %>%
  mutate(date = as.Date(date, format = "%Y-%m-%d"))  # Adjust the format if needed

combined_topics_with_dates <- bind_rows(
  snl_heatmap_data %>%
    select(show, date, economics, reproductive_rights, immigration) %>%
    pivot_longer(cols = c(economics, reproductive_rights, immigration), names_to = "topic", values_to = "mentioned_by") %>%
    mutate(show = "SNL"),
  
  tls_heatmap_data %>%
    select(show, date, economics, reproductive_rights, immigration) %>%
    pivot_longer(cols = c(economics, reproductive_rights, immigration), names_to = "topic", values_to = "mentioned_by") %>%
    mutate(show = "TLS"),
  
  lwt_heatmap_data %>%
    select(show, date, economics, reproductive_rights, immigration) %>%
    pivot_longer(cols = c(economics, reproductive_rights, immigration), names_to = "topic", values_to = "mentioned_by") %>%
    mutate(show = "LWT"),
  tds_heatmap_data %>%
    select(show, date, economics, reproductive_rights, immigration) %>%
    pivot_longer(cols = c(economics, reproductive_rights, immigration), names_to = "topic", values_to = "mentioned_by") %>%
    mutate(show = "TDS"),
)

# Filter out rows where no candidate was mentioned
combined_topics_with_dates <- combined_topics_with_dates %>%
  filter(mentioned_by != "None")

# Group by date, topic, and candidate, and count mentions
mentions_over_time <- combined_topics_with_dates %>%
  group_by(date, topic, mentioned_by) %>%
  summarize(total_mentions = n(), .groups = "drop")
```

# stacked area chart, cumulative over time
```{r}
# Step 1: Adjust the data to handle "Both" by duplicating rows
mentions_adjusted <- mentions_over_time %>%
  mutate(mentioned_by = ifelse(mentioned_by == "Both", "Trump", mentioned_by)) %>%
  bind_rows(
    mentions_over_time %>%
      filter(mentioned_by == "Both") %>%
      mutate(mentioned_by = "Harris")
  )

# Step 2: Group by date, topic, and candidate, and recalculate total mentions
mentions_adjusted <- mentions_adjusted %>%
  group_by(date, topic, mentioned_by) %>%
  summarize(total_mentions = sum(total_mentions), .groups = "drop")

# Step 3: Expand the data to include all dates for each topic and candidate
all_dates <- seq(min(mentions_adjusted$date), max(mentions_adjusted$date), by = "day")
mentions_expanded <- mentions_adjusted %>%
  group_by(topic, mentioned_by) %>%
  complete(date = all_dates, fill = list(total_mentions = 0)) %>%  # Fill missing dates with 0 mentions
  arrange(date) %>%
  ungroup()

# Step 4: Calculate cumulative mentions for each candidate over time
mentions_cumulative <- mentions_expanded %>%
  group_by(topic, mentioned_by) %>%
  mutate(cumulative_mentions = cumsum(total_mentions)) %>%
  ungroup()

# Step 5: Reorder the `mentioned_by` factor to bring Harris (blue) to the front
mentions_cumulative <- mentions_cumulative %>%
  mutate(mentioned_by = factor(mentioned_by, levels = c("Trump", "Harris")))

# Step 6: Create the cumulative area chart
cumulative_area_chart <- ggplot(mentions_cumulative, aes(x = date, y = cumulative_mentions, fill = mentioned_by)) +
  geom_area(alpha = 0.7, position = "identity") +  # Use position = "identity" for overlapping areas
  facet_wrap(~ topic, ncol = 1) +
  scale_fill_manual(values = c("Trump" = "red", "Harris" = "blue")) +  # Red and blue will blend into purple
  labs(
    title = "Cumulative Mentions of Election Topics Over Time",
    subtitle = "Overlapping Areas Highlight Shared Mentions by Trump and Harris Across All Analyzed Shows",
    x = "Date",
    y = "Cumulative Mentions",
    fill = "Candidate"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(face = "bold", size = 16),
    strip.text.x = element_text(face = "bold", size = 12),
    panel.background = element_rect(fill = "white", color = NA),  # White background
    plot.background = element_rect(fill = "white", color = NA)   # White background for the entire plot
  )

# Step 7: Print the chart
print(cumulative_area_chart)

# Step 8: Save the chart
ggsave("cumulative_mentions_over_time.png", plot = cumulative_area_chart, width = 12, height = 8, dpi = 300)
```

# Visualization that combines airtime with discussion of important topics overtime

```{r}
# Step 1: Prepare cumulative airtime data
airtime_cumulative <- combined_airtime %>%
  arrange(date) %>%
  group_by(date) %>%
  summarize(
    trump_airtime_cumulative = sum(total_trump_airtime_seconds, na.rm = TRUE),
    harris_airtime_cumulative = sum(total_harris_airtime_seconds, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  # Get cumulative sums across all dates
  mutate(
    trump_airtime_cumulative = cumsum(trump_airtime_cumulative),
    harris_airtime_cumulative = cumsum(harris_airtime_cumulative)
  )

# Step 2: Prepare cumulative mentions data (aggregated across all topics)
mentions_cumulative_all_topics <- mentions_cumulative %>%
  group_by(date, mentioned_by) %>%
  summarize(cumulative_mentions = sum(cumulative_mentions), .groups = "drop")

# Step 3: Combine datasets for plotting
combined_data <- airtime_cumulative %>%
  left_join(
    mentions_cumulative_all_topics %>%
      pivot_wider(
        names_from = mentioned_by,
        values_from = cumulative_mentions,
        names_prefix = "mentions_"
      ),
    by = "date"
  )

```


```{r}
# Step 4: Plot
ggplot(combined_data, aes(x = date)) +
  # Cumulative Airtime
  geom_line(aes(y = trump_airtime_cumulative, color = "Trump Airtime"), linewidth = 1.3) +
  geom_line(aes(y = harris_airtime_cumulative, color = "Harris Airtime"), linewidth = 1.3) +

  # Cumulative Mentions (rescaled)
  geom_line(aes(y = mentions_Trump * 60, color = "Trump Mentions"), linetype = "dashed", linewidth = 1.1) +
  geom_line(aes(y = mentions_Harris * 60, color = "Harris Mentions"), linetype = "dashed", linewidth = 1.1) +

  # Election Day reference line
  geom_vline(xintercept = as.Date("2024-11-05"), linetype = "dotted", color = "black", linewidth = 0.8) +
  annotate("text", x = as.Date("2024-11-05"), y = max(combined_data$trump_airtime_cumulative, na.rm = TRUE) * 0.95,
           label = "Election Day", angle = 90, vjust = -0.5, size = 4) +

  # Axis + color scales
  scale_y_continuous(
    name = "Cumulative Airtime (seconds)",
    sec.axis = sec_axis(~./60, name = "Cumulative Topic Mentions")
  ) +
  scale_color_manual(
    name = NULL,
    values = c(
      "Trump Airtime" = "#B22222", 
      "Harris Airtime" = "#1E3A8A",
      "Trump Mentions" = "#FA8072", 
      "Harris Mentions" = "#6495ED"
    )
  ) +

  # Labels + theme
  labs(
    title = "Candidate Airtime vs. Topic Mentions Over Time",
    subtitle = "Solid lines = Airtime (left axis) · Dashed lines = Topic Mentions (right axis)",
    x = "Date"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
    plot.subtitle = element_text(size = 13, hjust = 0.5),
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "white", color = NA),
    plot.background = element_rect(fill = "white", color = NA)
  )

# Save the plot
ggsave("airtime_vs_mentions_over_time_pretty.png", width = 12, height = 8, dpi = 300)

```


#stacked area vs frequency chart
```{r}
# Create the stacked area chart
ggplot(combined_data, aes(x = date)) +
  # Stacked area for cumulative airtime
  geom_area(aes(y = trump_airtime_cumulative, fill = "Trump Airtime"), position = "stack", alpha = 0.3) +
  geom_area(aes(y = harris_airtime_cumulative, fill = "Harris Airtime"), position = "stack", alpha = 0.3) +
  
  # Dashed lines for cumulative mentions (scaled for visual comparison)
  geom_line(aes(y = mentions_Trump * 60, color = "Trump Mentions"), 
            linetype = "dashed", linewidth = 1.2) +
  geom_line(aes(y = mentions_Harris * 60, color = "Harris Mentions"), 
            linetype = "dashed", linewidth = 1.2) +
  
  # Election Day marker
  geom_vline(xintercept = as.Date("2024-11-05"), 
             linetype = "longdash", color = "black", linewidth = 0.7) +
  annotate("text", x = as.Date("2024-11-05"), 
           y = max(combined_data$trump_airtime_cumulative + combined_data$harris_airtime_cumulative, na.rm = TRUE) * 0.9,
           label = "Election Day", angle = 90, hjust = -0.2, size = 4) +
  
  # Color scales
  scale_fill_manual(
    name = "Airtime (Area)",
    values = c("Trump Airtime" = "red", "Harris Airtime" = "blue")
  ) +
  scale_color_manual(
    name = "Mentions (Line)",
    values = c("Trump Mentions" = "darkred", "Harris Mentions" = "darkblue")
  ) +
  
  # Y-axis with secondary axis for mentions
  scale_y_continuous(
    name = "Cumulative Airtime (seconds)",
    sec.axis = sec_axis(~./60, name = "Cumulative Topic Mentions")
  ) +
  
  # Labels and styling
  labs(
    title = "Stacked Cumulative Airtime vs. Topic Mentions Over Time",
    subtitle = "Stacked areas show total airtime; dashed lines show topic mentions",
    x = "Date"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    legend.box = "vertical",
    panel.grid.minor = element_blank(),
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(face = "bold", size = 16, hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5),
    panel.background = element_rect(fill = "white", color = NA),
    plot.background = element_rect(fill = "white", color = NA)
  )

# Save the plot
ggsave("stacked_cumulative_airtime_mentions_timeline.png", width = 12, height = 8, dpi = 300)
```

