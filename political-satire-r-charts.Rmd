---
title: "political-satire-r-charts"
author: "Anna Fetter"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(lubridate)
library(stringr)
library(hms)
library(readr)
library(readxl)
library(patchwork)
library(ggforce)
```

### Step 1. Read in the data
```{r}
snl_airtime <- read_csv("data/snl-airtime.csv")
View(snl_airtime)
```

```{r}
#setting a theme so all charts look cohesive
theme_academic <- function(base_size = 14, base_family = "") {
  theme_minimal(base_size = base_size, base_family = base_family) +
    theme(
      strip.text = element_text(face = "bold", size = 10),
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank(),
      panel.grid.major.y = element_blank(),
      panel.grid.minor.y = element_blank(),
      panel.grid.major.x = element_line(color = "grey80", size = 0.3),
      panel.grid.minor.x = element_line(color = "grey90", size = 0.2),
      plot.title = element_text(face = "bold", size = 16, hjust = 0.5),
      plot.subtitle = element_text(size = 12, hjust = 0.5),
      axis.text.x = element_text(size = 10, color = "black"),
      plot.background = element_rect(fill = "white", color = NA)
    )
}
# Add a fixed aspect ratio to your chart
coord_fixed(ratio = 0.1)  # Adjust the ratio as needed

# Set the custom theme globally
theme_set(theme_academic())

# wrapper function to save charts with consistent dimensions
# Wrapper function for consistent chart styling and saving
save_academic_chart <- function(plot, filename, width = 8, height = 11, dpi = 300) {
  plot <- plot + theme_academic()  # Apply the custom theme without coord_fixed()
  ggsave(filename, plot = plot, width = width, height = height, dpi = dpi)
}
```
```{r}
#read in other chart for topic analysis
snl_topics <- read_excel("data/SNL-topics.xlsx")
View(snl_topics)
```

```{r}
class(snl_airtime$`harris air time stamps`)
```

```{r}
# cleaning the data to capture total airtime for Trump & Harris

# Function to calculate duration from timestamp ranges
calculate_duration <- function(time_range) {
  if (is.na(time_range) || time_range == "none" || time_range == "") return(0)
  
  # Process multiple ranges separated by "and"
  ranges <- unlist(strsplit(time_range, " and "))
  total_seconds <- 0
  
  for (range in ranges) {
    # Split start and end times
    times <- unlist(strsplit(range, "-"))
    if (length(times) != 2) next
    
    # Convert start time to seconds
    start_parts <- as.numeric(unlist(strsplit(times[1], ":")))
    start_seconds <- if (length(start_parts) == 2) start_parts[1] * 60 + start_parts[2] else start_parts[1]
    
    # Convert end time to seconds
    end_parts <- as.numeric(unlist(strsplit(times[2], ":")))
    end_seconds <- if (length(end_parts) == 2) end_parts[1] * 60 + end_parts[2] else end_parts[1]
    
    # Add duration to total
    total_seconds <- total_seconds + (end_seconds - start_seconds)
  }
  
  return(total_seconds)
}

# Function to process timestamps into a dataframe of start and end times
process_timestamps <- function(timestamps, candidate) {
  if (is.na(timestamps) || timestamps == "none" || timestamps == "") {
    # Return an empty dataframe with the correct structure
    return(data.frame(start = numeric(0), end = numeric(0), candidate = character(0)))
  }
  
  # Split the timestamps by "and" to handle multiple ranges
  ranges <- unlist(strsplit(timestamps, " and "))
  segments <- data.frame()
  
  for (range in ranges) {
    # Split each range into start and end times
    times <- unlist(strsplit(range, "-"))
    if (length(times) != 2) next
    
    # Convert start and end times to seconds
    start_parts <- as.numeric(unlist(strsplit(times[1], ":")))
    start_seconds <- if (length(start_parts) == 2) start_parts[1] * 60 + start_parts[2] else start_parts[1]
    
    end_parts <- as.numeric(unlist(strsplit(times[2], ":")))
    end_seconds <- if (length(end_parts) == 2) end_parts[1] * 60 + end_parts[2] else end_parts[1]
    
    # Add the segment to the dataframe
    segment <- data.frame(
      start = start_seconds,
      end = end_seconds,
      candidate = candidate
    )
    segments <- rbind(segments, segment)
  }
  
  return(segments)
}

str(snl_airtime$date)
```

### Airtime visualization for SNL
```{r}
# Process the SNL airtime data
snl_airtime_processed <- snl_airtime %>%
  mutate(
    # Calculate total airtime in seconds for Trump and Harris
    total_trump_airtime_seconds = sapply(`trump air time stamps`, calculate_duration),
    total_harris_airtime_seconds = sapply(`harris air time stamps`, calculate_duration),
    
    # Convert airtime to minutes for easier interpretation
    total_trump_airtime_minutes = round(total_trump_airtime_seconds / 60, 2),
    total_harris_airtime_minutes = round(total_harris_airtime_seconds / 60, 2),
    
    # Correctly parse "run time (total)" from HH:MM:SS to total seconds
    episode_length_seconds = sapply(`run time (total)`, function(runtime) {
      time_parts <- unlist(strsplit(as.character(runtime), ":"))
      # Handle HH:MM:SS format
      if (length(time_parts) == 3) {
        as.numeric(time_parts[1]) * 3600 +  # Hours to seconds
        as.numeric(time_parts[2]) * 60 +   # Minutes to seconds
        as.numeric(time_parts[3])          # Seconds
      } else if (length(time_parts) == 2) {
        as.numeric(time_parts[1]) * 60 +   # Minutes to seconds
        as.numeric(time_parts[2])          # Seconds
      } else {
        as.numeric(time_parts[1])          # Seconds only
      }
    }),
    
    # Convert the date column to Date format
    date = as.Date(date, format = "%d-%b-%y")
  )
# Rebuild all_segments for SNL
all_segments <- data.frame(
  start = numeric(0),
  end = numeric(0), 
  candidate = character(0),
  episode = character(0),
  stringsAsFactors = FALSE
)

# Loop through all episodes in snl_airtime_processed
for (i in 1:nrow(snl_airtime_processed)) {
  episode <- snl_airtime_processed[i, ]
  episode_title <- paste0(
    str_remove(episode$show, "SNL "),
    " (", format(episode$date, "%b %d, %Y"), ")"
  )
  
  # Process Trump and Harris airtime
  trump_segments <- process_timestamps(episode$`trump air time stamps`, "Trump")
  harris_segments <- process_timestamps(episode$`harris air time stamps`, "Harris")
  
  # Add episode title to each segment
  if (nrow(trump_segments) > 0) {
    trump_segments$episode <- episode_title
    all_segments <- rbind(all_segments, trump_segments)
  }
  
  if (nrow(harris_segments) > 0) {
    harris_segments$episode <- episode_title
    all_segments <- rbind(all_segments, harris_segments)
  }
}

# Create the episode_bars dataframe
episode_bars <- snl_airtime_processed %>%
  mutate(
    episode = paste0(
      str_remove(show, "SNL "),
      " (", format(date, "%b %d, %Y"), ")"
    ),
    episode_index = row_number()
  ) %>%
  select(episode, episode_length_seconds, date, episode_index)

  # Clean up the `episode` column in both data frames to ensure consistency
all_segments <- all_segments %>%
  mutate(
    episode = gsub("\"", "'", episode),  # Replace double quotes with single quotes
    episode = gsub("’", "'", episode),  # Replace fancy apostrophes with standard ones
    episode = gsub("“|”", "'", episode), # Replace fancy quotes with standard ones
    episode = str_trim(episode)          # Remove leading/trailing whitespace
  )

episode_bars <- episode_bars %>%
  mutate(
    episode = gsub("\"", "'", episode),
    episode = gsub("’", "'", episode),
    episode = gsub("“|”", "'", episode),
    episode = str_trim(episode)
  )

# Add the episode index to all_segments by joining with episode_bars
all_segments <- all_segments %>%
  left_join(
    episode_bars %>% select(episode, episode_index),
    by = "episode"
  )

  # Create the faceted visualization with pagination
total_pages <- ceiling(nrow(episode_bars) / 12)  # Calculate total pages (12 episodes per page)

for (page in 1:total_pages) {
  # Calculate which episode indices belong on this page
  page_indices <- ((page-1) * 12 + 1):(min(page * 12, nrow(episode_bars)))
  
  # Filter data for this page
  page_bars <- episode_bars %>% filter(episode_index %in% page_indices)
  page_segments <- all_segments %>% filter(episode_index %in% page_indices)
  
  # Generate the visualization for the current page
  paginated_vis <- ggplot() +
    # Draw the full episode bar (grey) for all episodes
    geom_rect(
      data = page_bars,
      aes(xmin = 0, xmax = episode_length_seconds, ymin = 0, ymax = 1, group = episode),
      fill = "grey90", color = "black", linewidth = 0.3
    ) +
    
    # Add Trump segments
    geom_rect(
      data = filter(page_segments, candidate == "Trump"),
      aes(xmin = start, xmax = end, ymin = 0.5, ymax = 1, group = episode),
      fill = "red", alpha = 0.8
    ) +
    
    # Add Harris segments
    geom_rect(
      data = filter(page_segments, candidate == "Harris"),
      aes(xmin = start, xmax = end, ymin = 0, ymax = 0.5, group = episode),
      fill = "blue", alpha = 0.8
    ) +
    
    # Add tick marks for every minute and every 15 seconds
    scale_x_continuous(
      breaks = seq(0, max(page_bars$episode_length_seconds, na.rm = TRUE), by = 60),  # Tick marks every minute
      minor_breaks = seq(0, max(page_bars$episode_length_seconds, na.rm = TRUE), by = 15),  # Minor tick marks every 15 seconds
      labels = function(x) sprintf("%d:%02d", x %/% 60, x %% 60)  # Format as mm:ss
    ) +
    
    # Facet by episode, ordered by the original data order
    facet_wrap(~ reorder(episode, episode_index), ncol = 1, scales = "free_x") +
    
    # Add labels and theme
    labs(
      title = paste0("Saturday Night Live Airtime by Candidate (Page ", page, ")"),
      subtitle = "Red: Trump Airtime | Blue: Harris Airtime",
      x = "Time (minutes:seconds)",
      y = NULL
    ) +
    theme_academic()
  
  # Save the current page
  save_academic_chart(paginated_vis, paste0("snl_airtime_faceted_page", page, ".pdf"), width = 8.5, height = 11)
}
```

### Topic analysis for snl
```{r}
#Now we're moving onto topic analysis, we need to clean the data first
# Convert "run time (total)" from POSIXct to seconds and MM:SS, THIS IS BROKEN
snl_topics_processed <- snl_topics %>%
  mutate(
    # Extract minutes and seconds from the POSIXct object
    episode_length_seconds = as.numeric(format(`run time (total)`, "%M")) * 60 +
                             as.numeric(format(`run time (total)`, "%S")),
    
    # Format back to MM:SS for display
    episode_length_formatted = sprintf("%d:%02d", floor(episode_length_seconds / 60), episode_length_seconds %% 60)
  )

#I noticed that the episode length is reading in as a date: fixing so it's run time
str(snl_topics$`run time (total)`)
```

## Cleaning topic analysis into a quantifiable format
```{r}
# step 1. make data quantifiable (ex. direct mentions = True, no direct mentions = False)
snl_topics_processed <- snl_topics %>%
  mutate(across(
    contains(c("reproductive", "immigration", "economics", "democracy")),
    ~ case_when(
        str_detect(., regex("no (direct|mentions|statements)", ignore_case = TRUE)) ~ FALSE,
        is.na(.) ~ NA,
        TRUE ~ TRUE
      ),
    .names = "mentioned_{.col}"
  ))
```


```{r}

#coding on my own to create the heatmap data

snl_heatmap_data <- snl_topics_processed %>% 
  mutate(
    economics = case_when(
      `mentioned_Trump Economics` == TRUE & `mentioned_Harris Economics` == FALSE ~ "Trump",
      `mentioned_Trump Economics` == FALSE & `mentioned_Harris Economics` == TRUE ~ "Harris",
      `mentioned_Trump Economics` == TRUE & `mentioned_Harris Economics` == TRUE ~ "Both",
      TRUE ~ "None"  # Default case when neither is TRUE
    ),
    reproductive_rights = case_when(
      `mentioned_Trump reproductive rights` == TRUE & `mentioned_Harris reproductive rights` == FALSE ~ "Trump",
      `mentioned_Trump reproductive rights` == FALSE & `mentioned_Harris reproductive rights` == TRUE ~ "Harris",
      `mentioned_Trump reproductive rights` == TRUE & `mentioned_Harris reproductive rights` == TRUE ~ "Both",
      TRUE ~ "None"  # Default case when neither is TRUE
    ),
    immigration = case_when(
      `mentioned_Trump immigration` == TRUE & `mentioned_Harris immigration` == FALSE ~ "Trump",
      `mentioned_Trump immigration` == FALSE & `mentioned_Harris immigration` == TRUE ~ "Harris",
      `mentioned_Trump immigration` == TRUE & `mentioned_Harris immigration` == TRUE ~ "Both",
      TRUE ~ "None"  # Default case when neither is TRUE
    ),
    democracy = case_when(
      `mentioned_Trump Democracy` == TRUE & `mentioned_Harris Democracy` == FALSE ~ "Trump",
      `mentioned_Trump Democracy` == FALSE & `mentioned_Harris Democracy` == TRUE ~ "Harris",
      `mentioned_Trump Democracy` == TRUE & `mentioned_Harris Democracy` == TRUE ~ "Both",
      TRUE ~ "None"  # Default case when neither is TRUE
    )
  ) %>% 
  select(show, date, economics, reproductive_rights, immigration, democracy)

head(snl_heatmap_data)
```

```{r}

# First, build labels like: 1 (Oct 01)
snl_heatmap_data <- snl_heatmap_data %>%
  arrange(date) %>%
  mutate(
    ep_num = row_number(),
    ep_label = paste0(ep_num, " (", format(date, "%b %d"), ")")
  )

# Pivot to long format for plotting
heatmap_long <- snl_heatmap_data %>%
  pivot_longer(
    cols = c(economics, reproductive_rights, immigration, democracy),
    names_to = "topic",
    values_to = "mentioned_by"
  )

# Color mapping
mention_colors <- c(
  "Trump" = "red",
  "Harris" = "blue",
  "Both" = "purple",
  "None" = "grey90"
)

# Build the heatmap
snl_heatmap_plot <- ggplot(heatmap_long, aes(x = factor(ep_label, levels = unique(snl_heatmap_data$ep_label)), 
                                         y = fct_rev(topic), fill = mentioned_by)) +
  geom_tile(color = "white", linewidth = 0.5) +
  scale_fill_manual(values = mention_colors, name = "Mentioned By") +
  labs(
    title = "Saturday Night Live Mentions by Topic and Candidate",
    x = "Episode Number (Air Date)",
    y = "Topic"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid = element_blank(),
    plot.background = element_rect(fill = "white", color = NA)
  ) +
  geom_vline(
    xintercept = which(snl_heatmap_data$date == as.Date("2024-11-05")),
    linetype = "dashed", color = "black"
  )

# Save the final version
ggsave("snl_heatmap_topics.png", plot = snl_heatmap_plot, width = 12, height = 6, dpi = 300)
```

## Repeat the analysis for LWT
```{r}
# Read in data
LWT_airtime <- read_csv("data/LWT-airtime.csv")
LWT_topics <- read_excel("data/LWT-topics.xlsx")
```

```{r}
summary(LWT_airtime)
```

```{r}
# Step 1: Process the LWT airtime data with corrected runtime parsing for HH:MM:SS
LWT_airtime_processed <- LWT_airtime %>%
  mutate(
    # Correctly parse "run time (total)" from HH:MM:SS to total seconds
    episode_length_seconds = sapply(`run time (total)`, function(runtime) {
      time_parts <- unlist(strsplit(as.character(runtime), ":"))
      # Handle HH:MM:SS format
      if (length(time_parts) == 3) {
        as.numeric(time_parts[1]) * 3600 +  # Hours to seconds
        as.numeric(time_parts[2]) * 60 +   # Minutes to seconds
        as.numeric(time_parts[3])          # Seconds
      } else if (length(time_parts) == 2) {
        as.numeric(time_parts[1]) * 60 +   # Minutes to seconds
        as.numeric(time_parts[2])          # Seconds
      } else {
        as.numeric(time_parts[1])          # Seconds only
      }
    }),
    
    # Calculate total airtime in seconds for Trump and Harris
    total_trump_airtime_seconds = sapply(`trump air time stamps`, calculate_duration),
    total_harris_airtime_seconds = sapply(`harris air time stamps`, calculate_duration),
    
    # Convert airtime to minutes for easier interpretation
    total_trump_airtime_minutes = round(total_trump_airtime_seconds / 60, 2),
    total_harris_airtime_minutes = round(total_harris_airtime_seconds / 60, 2)
  )

# Convert the date column to Date format
LWT_airtime_processed <- LWT_airtime_processed %>%
  mutate(date = as.Date(date, format = "%d-%b-%y"))
```

```{r}
#create airtime visualizations
# Step 2: Process all episodes into segments
all_segments_lwt <- data.frame(
  start = numeric(0),
  end = numeric(0), 
  candidate = character(0),
  episode = character(0),
  stringsAsFactors = FALSE
)

for (i in 1:nrow(LWT_airtime_processed)) {
  episode <- LWT_airtime_processed[i, ]
  episode_title <- paste0(
    episode$show,
    " (", format(episode$date, "%b %d, %Y"), ")"
  )
  
  # Process Trump and Harris airtime
  trump_segments <- process_timestamps(episode$`trump air time stamps`, "Trump")
  harris_segments <- process_timestamps(episode$`harris air time stamps`, "Harris")
  
  # Add episode title to each segment
  if (nrow(trump_segments) > 0) {
    trump_segments$episode <- episode_title
    all_segments_lwt <- rbind(all_segments_lwt, trump_segments)
  }
  
  if (nrow(harris_segments) > 0) {
    harris_segments$episode <- episode_title
    all_segments_lwt <- rbind(all_segments_lwt, harris_segments)
  }
}
```

```{r}
# Check the structure of the date column
str(LWT_airtime_processed$date)

# View unique values in the date column
unique(LWT_airtime_processed$date)
```

```{r}
# Step 3: Create the episode_bars dataframe
episode_bars_lwt <- LWT_airtime_processed %>%
  mutate(
    episode = paste0(
      show,
      " (", format(date, "%b %d, %Y"), ")"
    )
  ) %>%
  select(episode, episode_length_seconds, date) %>%
  arrange(date)  # Sort by air date

# Set episode factor levels in order of air date
episode_bars_lwt <- episode_bars_lwt %>%
  mutate(episode = factor(episode, levels = episode))
```

```{r}
# Step 4: Create the faceted visualization
all_episodes_vis_lwt <- ggplot() +
  # Draw the full episode bar (grey) for all episodes
  geom_rect(
    data = episode_bars_lwt,
    aes(xmin = 0, xmax = episode_length_seconds, ymin = 0, ymax = 1, group = episode),
    fill = "grey90", color = "black", size = 0.3
  ) +
  
  # Add Trump segments
  geom_rect(
    data = filter(all_segments_lwt, candidate == "Trump"),
    aes(xmin = start, xmax = end, ymin = 0.5, ymax = 1, group = episode),
    fill = "red", alpha = 0.8
  ) +
  
  # Add Harris segments
  geom_rect(
    data = filter(all_segments_lwt, candidate == "Harris"),
    aes(xmin = start, xmax = end, ymin = 0, ymax = 0.5, group = episode),
    fill = "blue", alpha = 0.8
  ) +
  
  # Add tick marks for every minute and every 15 seconds
scale_x_continuous(
    breaks = seq(0, max(episode_bars_lwt$episode_length_seconds), by = 300),  # Tick marks every 5 minutes (300 seconds)
    minor_breaks = seq(0, max(episode_bars_lwt$episode_length_seconds), by = 60),  # Minor tick marks every 1 minute
    labels = function(x) sprintf("%d:%02d", x %/% 60, x %% 60)  # Format as mm:ss
  ) +
  
  # Facet by episode, in air-date order
  facet_wrap(~ episode, ncol = 1, scales = "free_x") +
  
  # Add labels and theme
  labs(
    title = "Last Week Tonight with John Oliver Airtime by Candidate",
    subtitle = "Red: Trump Airtime | Blue: Harris Airtime",
    x = "Time (minutes:seconds)",
    y = NULL
  ) +
  theme_academic()  # Apply the custom theme

# Save the chart without coord_fixed()
all_episodes_vis_lwt <- all_episodes_vis_lwt +
  facet_wrap(~ episode, ncol = 1, scales = "free_x")  # Keep free_x for independent scales

# Save the chart
save_academic_chart(all_episodes_vis_lwt, "lwt_airtime_faceted.pdf", width = 8, height = 11)
```

```{r}
#now creating the topic heatmap for LWT
# Step 1: Process the LWT topics data
LWT_topics_processed <- LWT_topics %>%
  mutate(across(
    contains(c("reproductive", "immigration", "economics", "democracy")),
    ~ case_when(
        str_detect(., regex("No (mention|statements)", ignore_case = TRUE)) ~ FALSE,  # Match "no mentions" or "no statements"
        is.na(.) ~ NA,  # Keep NA as NA
        TRUE ~ TRUE  # Everything else is TRUE
      ),
    .names = "mentioned_{.col}"  # Create new columns with "mentioned_" prefix
  ))

# Create heatmap data
# Step 2: Create the heatmap dataset
lwt_heatmap_data <- LWT_topics_processed %>%
  mutate(
    economics = case_when(
      `mentioned_Trump Economics` == TRUE & `mentioned_Harris Economics` == FALSE ~ "Trump",
      `mentioned_Trump Economics` == FALSE & `mentioned_Harris Economics` == TRUE ~ "Harris",
      `mentioned_Trump Economics` == TRUE & `mentioned_Harris Economics` == TRUE ~ "Both",
      TRUE ~ "None"  # Default case when neither is TRUE
    ),
    reproductive_rights = case_when(
      `mentioned_Trump reproductive rights` == TRUE & `mentioned_Harris reproductive rights` == FALSE ~ "Trump",
      `mentioned_Trump reproductive rights` == FALSE & `mentioned_Harris reproductive rights` == TRUE ~ "Harris",
      `mentioned_Trump reproductive rights` == TRUE & `mentioned_Harris reproductive rights` == TRUE ~ "Both",
      TRUE ~ "None"  # Default case when neither is TRUE
    ),
    immigration = case_when(
      `mentioned_Trump immigration` == TRUE & `mentioned_Harris immigration` == FALSE ~ "Trump",
      `mentioned_Trump immigration` == FALSE & `mentioned_Harris immigration` == TRUE ~ "Harris",
      `mentioned_Trump immigration` == TRUE & `mentioned_Harris immigration` == TRUE ~ "Both",
      TRUE ~ "None"  # Default case when neither is TRUE
    ),
    democracy = case_when(
      `mentioned_Trump Democracy` == TRUE & `mentioned_Harris Democracy` == FALSE ~ "Trump",
      `mentioned_Trump Democracy` == FALSE & `mentioned_Harris Democracy` == TRUE ~ "Harris",
      `mentioned_Trump Democracy` == TRUE & `mentioned_Harris Democracy` == TRUE ~ "Both",
      TRUE ~ "None"  # Default case when neither is TRUE
    )
  ) %>%
  select(show, date, economics, reproductive_rights, immigration, democracy)

unique(LWT_topics$date)

lwt_heatmap_data <- lwt_heatmap_data %>%
  mutate(date = as.Date(date, format = "%d-%b-%y"))
  
# View the first few rows of the heatmap dataset
head(lwt_heatmap_data)
```

```{r}
# Step 3: Prepare the data for plotting
lwt_heatmap_data <- lwt_heatmap_data %>%
  arrange(date) %>%
  mutate(
    ep_num = row_number(),  # Create episode numbers
    ep_label = paste0(ep_num, " (", format(date, "%b %d"), ")")  # Create episode labels
  )



# Pivot to long format
heatmap_long <- lwt_heatmap_data %>%
  pivot_longer(
    cols = c(economics, reproductive_rights, immigration, democracy),
    names_to = "topic",
    values_to = "mentioned_by"
  )
```

```{r}
#create the heatmap
# Step 4: Create the heatmap
lwt_heatmap_plot <- ggplot(heatmap_long, 
                          aes(x = factor(ep_label, levels = unique(lwt_heatmap_data$ep_label)), 
                              y = fct_rev(topic), fill = mentioned_by)) +
  geom_tile(color = "white", linewidth = 0.5) +
  scale_fill_manual(values = mention_colors, name = "Mentioned By") +
  labs(
    title = "Last Week Tonight with John Oliver Mentions by Topic and Candidate",
    x = "Episode Number (Air Date)",
    y = "Topic"
  ) +
  theme_academic() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.y = element_text(size = 10, color = "black"), # Explicitly show y-axis text
    panel.grid = element_blank(),
    plot.background = element_rect(fill = "white", color = NA)
  )

# Print the heatmap
print(lwt_heatmap_plot)

# Save the heatmap
ggsave("lwt_heatmap_topics.png", plot = lwt_heatmap_plot, width = 12, height = 6, dpi = 300)
```

#now repeating the analysis for The Late Show with Stephen Colbert
```{r}
#read in data
tls_airtime <- read_csv("data/tls-airtime.csv")
tls_topics <- read_excel("data/tls-topics.xlsx")

# Fix the run time column in tls_airtime
tls_airtime <- tls_airtime %>%
  mutate(
    # Convert "run time (total)" from MM:SS to total seconds
    episode_length_seconds = sapply(`run time`, function(runtime) {
      time_parts <- unlist(strsplit(as.character(runtime), ":"))
      if (length(time_parts) == 2) {
        # Parse as MM:SS
        as.numeric(time_parts[1]) * 60 + as.numeric(time_parts[2])
      } else if (length(time_parts) == 3) {
        # Handle HH:MM:SS (if present)
        as.numeric(time_parts[1]) * 3600 + as.numeric(time_parts[2]) * 60 + as.numeric(time_parts[3])
      } else {
        NA  # Handle unexpected formats
      }
    })
  ) 
tls_airtime <- tls_airtime %>%
  mutate(date = as.Date(date, format = "%d-%b-%y"))
```

#airtime visualization
```{r}
# Process airtime for Trump and Harris
tls_airtime_processed <- tls_airtime %>%
  mutate(
    # Calculate total airtime in seconds for Trump and Harris
    total_trump_airtime_seconds = sapply(`trump air time stamps`, calculate_duration),
    total_harris_airtime_seconds = sapply(`harris air time stamps`, calculate_duration),
    
    # Convert airtime to minutes for easier interpretation
    total_trump_airtime_minutes = round(total_trump_airtime_seconds / 60, 2),
    total_harris_airtime_minutes = round(total_harris_airtime_seconds / 60, 2)
  )

# Process all episodes into segments
all_segments_tls <- data.frame(
  start = numeric(0),
  end = numeric(0), 
  candidate = character(0),
  episode = character(0),
  stringsAsFactors = FALSE
)

for (i in 1:nrow(tls_airtime_processed)) {
  episode <- tls_airtime_processed[i, ]
  episode_title <- paste0(
    episode$show,
    " (", format(episode$date, "%b %d, %Y"), ")"
  )
  
  # Process Trump and Harris airtime
  trump_segments <- process_timestamps(episode$`trump air time stamps`, "Trump")
  harris_segments <- process_timestamps(episode$`harris air time stamps`, "Harris")
  
  # Add episode title to each segment
  if (nrow(trump_segments) > 0) {
    trump_segments$episode <- episode_title
    all_segments_tls <- rbind(all_segments_tls, trump_segments)
  }
  
  if (nrow(harris_segments) > 0) {
    harris_segments$episode <- episode_title
    all_segments_tls <- rbind(all_segments_tls, harris_segments)
  }
}

# Create the episode_bars dataframe
episode_bars_tls <- tls_airtime_processed %>%
  mutate(
    episode = paste0(
      show,
      " (", format(date, "%b %d, %Y"), ")"
    )
  ) %>%
  select(episode, episode_length_seconds, date) %>%
  arrange(date)  # Sort by air date


# Explicitly set factor levels for the episode column based on the date order
episode_bars_tls <- episode_bars_tls %>%
  mutate(episode = factor(episode, levels = unique(episode)))

# Apply the same factor levels to all_segments_tls
all_segments_tls <- all_segments_tls %>%
  mutate(episode = factor(episode, levels = levels(episode_bars_tls$episode)))

# Clean up quotes and apostrophes in episode titles
episode_bars_tls <- episode_bars_tls %>%
  mutate(
    episode = gsub("\"", "'", episode),  # Replace double quotes with single quotes
    episode = gsub("’", "'", episode),  # Replace fancy apostrophes with standard ones
    episode = gsub("“|”", "'", episode) # Replace fancy quotes with standard ones
  )

all_segments_tls <- all_segments_tls %>%
  mutate(
    episode = gsub("\"", "'", episode),
    episode = gsub("’", "'", episode),
    episode = gsub("“|”", "'", episode)
  )
```

```{r}
#should output episodes in chronological order
levels(episode_bars_tls$episode)
```

```{r}
# Add a numeric index to tls_airtime_processed to preserve the date order
tls_airtime_processed <- tls_airtime_processed %>%
  arrange(date) %>%
  mutate(episode_index = row_number())

# Create episode_bars_tls with the same index
episode_bars_tls <- tls_airtime_processed %>%
  mutate(
    episode = paste0(
      show,
      " (", format(date, "%b %d, %Y"), ")"
    ),
    episode_index = row_number()
  ) %>%
  select(episode, episode_length_seconds, date, episode_index)

# Add the episode index to all_segments_tls by joining with episode_bars_tls
all_segments_tls <- all_segments_tls %>%
  left_join(
    episode_bars_tls %>% select(episode, episode_index),
    by = "episode"
  )

# Create the faceted visualization with pagination using episode_index for ordering
total_pages <- ceiling(length(unique(episode_bars_tls$episode)) / 12)  # Calculate total pages (12 episodes per page)

# Find the maximum episode length across all episodes
max_episode_length <- max(episode_bars_tls$episode_length_seconds, na.rm = TRUE)

for (page in 1:total_pages) {
  # Calculate which episode indices belong on this page
  page_indices <- ((page-1) * 12 + 1):(min(page * 12, nrow(episode_bars_tls)))
  
  # Filter data for this page
  page_bars <- episode_bars_tls %>% filter(episode_index %in% page_indices)
  page_segments <- all_segments_tls %>% filter(episode_index %in% page_indices)
  
  # Generate the visualization for the current page
  paginated_vis <- ggplot() +
    # Draw the full episode bar (grey) for all episodes
    geom_rect(
      data = page_bars,
      aes(xmin = 0, xmax = episode_length_seconds, ymin = 0, ymax = 1, group = episode),
      fill = "grey90", color = "black", linewidth = 0.3
    ) +
    
    # Add Trump segments
    geom_rect(
      data = filter(page_segments, candidate == "Trump"),
      aes(xmin = start, xmax = end, ymin = 0.5, ymax = 1, group = episode),
      fill = "red", alpha = 0.8
    ) +
    
    # Add Harris segments
    geom_rect(
      data = filter(page_segments, candidate == "Harris"),
      aes(xmin = start, xmax = end, ymin = 0, ymax = 0.5, group = episode),
      fill = "blue", alpha = 0.8
    ) +
    
    # Add tick marks for every minute and every 15 seconds
    scale_x_continuous(
      breaks = seq(0, max(episode_bars_tls$episode_length_seconds, na.rm = TRUE), by = 60),  # Tick marks every minute
      minor_breaks = seq(0, max(episode_bars_tls$episode_length_seconds, na.rm = TRUE), by = 15),  # Minor tick marks every 15 seconds
      labels = function(x) sprintf("%d:%02d", x %/% 60, x %% 60)  # Format as mm:ss
    ) +
    
    # Facet by episode, ordered by the original data order
    facet_wrap(~ reorder(episode, episode_index), ncol = 1, scales = "free_x") +
    
    # Add labels and theme
    labs(
      title = "The Late Show with Stephen Colbert Airtime by Candidate",
      subtitle = "Red: Trump Airtime | Blue: Harris Airtime",
      x = "Time (minutes:seconds)",
      y = NULL
    ) +
    theme_academic()
  
  # Save the current page
  save_academic_chart(paginated_vis, paste0("tls_airtime_faceted_page", page, ".pdf"), width = 8.5, height = 11)
}
```

#now build topic visualizations for TLS
```{r}
# Step 1: Process the TLS topics data
tls_topics_processed <- tls_topics %>%
  mutate(across(
    contains(c("reproductive", "immigration", "economics", "democracy")),
    ~ case_when(
        str_detect(., regex("No (mention|statements|direct|specific)", ignore_case = TRUE)) ~ FALSE,
        is.na(.) ~ NA,
        TRUE ~ TRUE
      ),
    .names = "mentioned_{.col}"
  ))

# Step 2: Create the heatmap dataset
tls_heatmap_data <- tls_topics_processed %>%
  mutate(
    economics = case_when(
      `mentioned_Trump Economics` == TRUE & `mentioned_Harris Economics` == FALSE ~ "Trump",
      `mentioned_Trump Economics` == FALSE & `mentioned_Harris Economics` == TRUE ~ "Harris",
      `mentioned_Trump Economics` == TRUE & `mentioned_Harris Economics` == TRUE ~ "Both",
      TRUE ~ "None"  # Default case when neither is TRUE
    ),
    reproductive_rights = case_when(
      `mentioned_Trump reproductive rights` == TRUE & `mentioned_Harris reproductive rights` == FALSE ~ "Trump",
      `mentioned_Trump reproductive rights` == FALSE & `mentioned_Harris reproductive rights` == TRUE ~ "Harris",
      `mentioned_Trump reproductive rights` == TRUE & `mentioned_Harris reproductive rights` == TRUE ~ "Both",
      TRUE ~ "None"
    ),
    immigration = case_when(
      `mentioned_Trump immigration` == TRUE & `mentioned_Harris immigration` == FALSE ~ "Trump",
      `mentioned_Trump immigration` == FALSE & `mentioned_Harris immigration` == TRUE ~ "Harris",
      `mentioned_Trump immigration` == TRUE & `mentioned_Harris immigration` == TRUE ~ "Both",
      TRUE ~ "None"
    )
  ) %>%
  select(show, date, economics, reproductive_rights, immigration)

# Make sure date is in the correct format
tls_heatmap_data <- tls_heatmap_data %>%
  mutate(date = as.Date(date, format = "%d-%b-%y"))

# Step 3: Prepare the data for plotting
tls_heatmap_data <- tls_heatmap_data %>%
  arrange(date) %>%
  mutate(
    ep_num = row_number(),  # Create episode numbers
    ep_label = paste0(ep_num, " (", format(date, "%b %d"), ")")  # Create episode labels
  )

# Pivot to long format
tls_heatmap_long <- tls_heatmap_data %>%
  pivot_longer(
    cols = c(economics, reproductive_rights, immigration),
    names_to = "topic",
    values_to = "mentioned_by"
  )

# Step 4: Create the heatmap
# Fix for TLS heatmap
tls_heatmap_plot <- ggplot(tls_heatmap_long, 
                          aes(x = factor(ep_label, levels = unique(tls_heatmap_data$ep_label)), 
                              y = fct_rev(topic), fill = mentioned_by)) +
  geom_tile(color = "white", linewidth = 0.5) +
  scale_fill_manual(values = mention_colors, name = "Mentioned By") +
  labs(
    title = "The Late Show with Stephen Colbert Mentions by Topic and Candidate",
    x = "Episode Number (Air Date)",
    y = "Topic"
  ) +
  theme_academic() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.y = element_text(size = 10, color = "black"), # Explicitly show y-axis text
    panel.grid = element_blank(),
    plot.background = element_rect(fill = "white", color = NA)
  ) +
  geom_vline(
    xintercept = which(tls_heatmap_data$date == as.Date("2024-11-05")),
    linetype = "dashed", color = "black"
  )

# Print the heatmap
print(tls_heatmap_plot)

# Save the heatmap
ggsave("tls_heatmap_topics.png", plot = tls_heatmap_plot, width = 12, height = 6, dpi = 300)
```




### Building cumulative visualizations, exploring percentages that each candidate got airtime

```{r}
# Aggregate airtime by date for SNL to avoide "double stacking"
snl_airtime_aggregated <- snl_airtime_processed %>%
  group_by(date) %>%
  summarize(
    total_trump_airtime_seconds = sum(total_trump_airtime_seconds, na.rm = TRUE),
    total_harris_airtime_seconds = sum(total_harris_airtime_seconds, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(show = "SNL")  # Add a column to identify the show
```

#### Need to make this prettier
```{r}
# Combine aggregated SNL data with LWT data
combined_airtime <- bind_rows(
  snl_airtime_aggregated,
  LWT_airtime_processed %>%
    select(date, total_trump_airtime_seconds, total_harris_airtime_seconds) %>%
    mutate(show = "LWT")
)

# Calculate relative airtime percentages
combined_relative_airtime <- combined_airtime %>%
  mutate(
    total_candidate_airtime_seconds = total_trump_airtime_seconds + total_harris_airtime_seconds,
    trump_airtime_percentage = ifelse(total_candidate_airtime_seconds > 0, 
                                       (total_trump_airtime_seconds / total_candidate_airtime_seconds) * 100, 
                                       NA),
    harris_airtime_percentage = ifelse(total_candidate_airtime_seconds > 0, 
                                        (total_harris_airtime_seconds / total_candidate_airtime_seconds) * 100, 
                                        NA)
  ) %>%
  select(show, date, trump_airtime_percentage, harris_airtime_percentage)

# Pivot to long format for plotting
combined_relative_airtime_long <- combined_relative_airtime %>%
  pivot_longer(
    cols = c(trump_airtime_percentage, harris_airtime_percentage),
    names_to = "candidate",
    values_to = "percentage"
  ) %>%
  mutate(
    candidate = recode(candidate, 
                        "trump_airtime_percentage" = "Trump", 
                        "harris_airtime_percentage" = "Harris"),
    date = as.factor(date)  # Treat date as a factor for proper ordering
  )

# Create the stacked bar chart
combined_stacked_bar_chart <- ggplot(combined_relative_airtime_long, aes(x = factor(date), y = percentage, fill = candidate)) +
  geom_bar(stat = "identity", color = "black") +
  scale_fill_manual(values = c("Trump" = "red", "Harris" = "blue"), name = "Candidate") +
  geom_text(aes(label = paste0(round(percentage, 1), "%")), 
            position = position_stack(vjust = 0.5), size = 3) +  # Add percentage labels
  facet_wrap(~ show, scales = "free_x") +  # Facet by show with independent x-axis scales
  labs(
    title = "Relative Airtime for Trump and Harris Across SNL and LWT",
    subtitle = "Proportion of airtime when one of the candidates was mentioned",
    x = "Episode Date",
    y = "Percentage of Airtime"
  ) +
  theme_academic() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

# Print the combined stacked bar chart
print(combined_stacked_bar_chart)

# Save the combined stacked bar chart
ggsave("combined_relative_airtime_cleaned.png", plot = combined_stacked_bar_chart, width = 12, height = 8, dpi = 300)
```

```{r}
# Create the grouped bar chart
grouped_bar_chart <- ggplot(combined_relative_airtime_long, aes(x = date, y = percentage, fill = candidate)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8), color = "black") +
  scale_fill_manual(values = c("Trump" = "red", "Harris" = "blue"), name = "Candidate") +
  facet_wrap(~ show, ncol = 1, scales = "free_x") +  # Separate by show
  geom_text(aes(label = paste0(round(percentage, 1), "%")), 
            position = position_dodge(width = 0.8), vjust = -0.5, size = 3) +  # Add percentage labels
  labs(
    title = "Relative Airtime for Trump and Harris by Date",
    subtitle = "Proportion of airtime when one of the candidates was mentioned",
    x = "Date",
    y = "Percentage of Airtime"
  ) +
  theme_academic() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(face = "bold", size = 12)
  )

# Print the grouped bar chart
print(grouped_bar_chart)

# Save the grouped bar chart
ggsave("grouped_relative_airtime_by_date.png", plot = grouped_bar_chart, width = 12, height = 8, dpi = 300)

```

cumulative airline visualizations
```{r}
# Combine all processed airtime dataframes into one
combined_airtime <- bind_rows(
  snl_airtime_processed %>%
    select(date, total_trump_airtime_seconds, total_harris_airtime_seconds) %>%
    mutate(show = "SNL"),
  
  tls_airtime_processed %>%
    select(date, total_trump_airtime_seconds, total_harris_airtime_seconds) %>%
    mutate(show = "TLS"),
  
  LWT_airtime_processed %>%
    select(date, total_trump_airtime_seconds, total_harris_airtime_seconds) %>%
    mutate(show = "LWT")
)


# Group by week and calculate total airtime for each candidate
weekly_airtime <- combined_airtime %>%
  mutate(week = floor_date(date, "week")) %>%  # Group by week
  group_by(week, show) %>%
  summarize(
    total_trump_airtime_seconds = sum(total_trump_airtime_seconds, na.rm = TRUE),
    total_harris_airtime_seconds = sum(total_harris_airtime_seconds, na.rm = TRUE),
    .groups = "drop"
  )

# Calculate percentage of airtime for Harris
weekly_percentages <- weekly_airtime %>%
  mutate(
    total_candidate_airtime_seconds = total_trump_airtime_seconds + total_harris_airtime_seconds,
    percent_harris = ifelse(total_candidate_airtime_seconds > 0,
                            (total_harris_airtime_seconds / total_candidate_airtime_seconds) * 100,
                            NA)
  ) %>%
  select(week, show, percent_harris)

# Average percentages across shows
average_weekly_percentages <- weekly_percentages %>%
  group_by(week) %>%
  summarize(avg_percent_harris = mean(percent_harris, na.rm = TRUE), .groups = "drop")

library(ggplot2)

# Create the horizontal bar plot
airtime_by_week <- ggplot(average_weekly_percentages, aes(x = avg_percent_harris, y = fct_rev(as.factor(week)))) +
  geom_bar(stat = "identity", fill = "blue", alpha = 0.8) +
  geom_vline(xintercept = 50, linetype = "dashed", color = "red") +  # Add 50% reference line
  scale_x_continuous(labels = scales::percent_format(scale = 1)) +  # Format x-axis as percentages
  labs(
    title = "Weekly Percentage of Airtime for Kamala Harris",
    subtitle = "Averaged across SNL, LWT, and TLS",
    x = "Percentage of Airtime for Harris",
    y = "Week"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 10),
    plot.title = element_text(face = "bold", size = 16, hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5)
  )

# Print the plot
print(airtime_by_week)

# Save the plot
ggsave("percent_candidate_airtime_weekly.png", plot = airtime_by_week, width = 10, height = 8, dpi = 300)
```

```{r}

# Combine all processed airtime dataframes into one
combined_airtime <- bind_rows(
  snl_airtime_processed %>%
    select(date, total_trump_airtime_seconds, total_harris_airtime_seconds) %>%
    mutate(show = "SNL"),
  
  tls_airtime_processed %>%
    select(date, total_trump_airtime_seconds, total_harris_airtime_seconds) %>%
    mutate(show = "TLS"),
  
  LWT_airtime_processed %>%
    select(date, total_trump_airtime_seconds, total_harris_airtime_seconds) %>%
    mutate(show = "LWT")
)

# Group by week and calculate total airtime for each candidate
weekly_airtime <- combined_airtime %>%
  mutate(week = floor_date(date, "week")) %>%  # Group by week
  group_by(week, show) %>%
  summarize(
    total_trump_airtime_seconds = sum(total_trump_airtime_seconds, na.rm = TRUE),
    total_harris_airtime_seconds = sum(total_harris_airtime_seconds, na.rm = TRUE),
    .groups = "drop"
  )

# Calculate percentage of airtime for each candidate
weekly_percentages <- weekly_airtime %>%
  mutate(
    total_candidate_airtime_seconds = total_trump_airtime_seconds + total_harris_airtime_seconds,
    percent_harris = ifelse(total_candidate_airtime_seconds > 0,
                            (total_harris_airtime_seconds / total_candidate_airtime_seconds) * 100,
                            NA),
    percent_trump = 100 - percent_harris  # Remaining percentage for Trump
  ) %>%
  select(week, show, percent_harris, percent_trump)

# Combine into one row per week with both candidate shares
average_weekly_percentages <- weekly_percentages %>%
  group_by(week) %>%
  summarize(
    avg_percent_harris = mean(percent_harris, na.rm = TRUE),
    avg_percent_trump = mean(percent_trump, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  pivot_longer(
    cols = c(avg_percent_harris, avg_percent_trump),
    names_to = "candidate",
    values_to = "percentage"
  ) %>%
  mutate(
    candidate = recode(candidate, 
                       "avg_percent_harris" = "Harris", 
                       "avg_percent_trump" = "Trump")
  )

# Get the position of the election week factor on the Y-axis
election_week <- as.Date("2024-11-05")
election_week_floor <- floor_date(election_week, "week")

# Convert weeks to factor in the same order used in the plot
week_levels <- sort(unique(average_weekly_percentages$week), decreasing = TRUE)
election_week_index <- which(week_levels == election_week_floor)

# Now plot with a horizontal line at that Y-position
airtime_by_week <- ggplot(average_weekly_percentages, aes(x = percentage, y = fct_rev(as.factor(week)), fill = candidate)) +
  geom_col(position = "stack", alpha = 0.9) +
  geom_hline(yintercept = election_week_index, linetype = "dashed", color = "black", size = 1) +  # Election Day line
  annotate("text", x = 100, y = election_week_index, label = "Election Day", hjust = 0, vjust = -0.5, size = 4, color = "black") +
  scale_x_continuous(labels = function(x) paste0(x, "%"), limits = c(0, 100)) +
  labs(
    title = "Weekly Distribution of Airtime Between Trump and Harris",
    subtitle = "Averaged across SNL, TLS, and LWT",
    x = "Share of Candidate Airtime",
    y = "Week"
  ) +
  scale_fill_manual(values = c("Trump" = "red", "Harris" = "blue")) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 10),
    plot.title = element_text(face = "bold", size = 16, hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5)
  ) + coord_cartesian(clip = "off")


# Print the plot
print(airtime_by_week)

ggsave(
  filename = "weekly_airtime_distribution.png",
  plot = airtime_by_week,
  width = 12,
  height = 8,
  dpi = 300
)
```